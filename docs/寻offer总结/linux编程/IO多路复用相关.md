## Socket模型

要想客户端和服务器能在网络中通信，那必须得使用 `Socket` 编程，`Socket`可以跨主机间通信。

创建 `Socket` 的时候，可以指定网络层使用的是 `IPv4` 还是 `IPv6`，传输层使用的是 `TCP` 还是 `UDP`。

对于 TCP 的 Socket 编程来说

### 服务端的 Socket 编程过程

（1）服务端首先调用 `socket()` 函数，创建网络协议为 `IPv4`，以及传输协议为 `TCP` 的 `Socket` ，接着调用 `bind()` 函数，给这个 `Socket` 绑定一个 `IP` 地址和端口

- 绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。
- 绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，只有相应的网卡收到数据后，才会发给我们；

（2）绑定完 IP 地址和端口号后，就可以调用 `listen()` 函数进行监听，这个时候如果我们要判定服务器中一个网络程序有没有启动，可以通过 `netstat` 命令查看对应的端口号是否有被监听。

（3）服务端进入了监听状态后，通过调用 `accept()` 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。

**那客户端是怎么发起连接的呢**？

（1）客户端在创建好 `Socket` 后，调用 `connect()` 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后 `TCP` 三次握手就开始了。

（2）在 `TCP` 连接的过程中，服务器的内核实际上为每个 `Socket` 维护了两个队列：

一个是`TCP`半连接队列，一个是`TCP`全连接队列。`TCP`半连接队列就是还没完成三次握手的链接，`TCP`全连接队列就是已经完成三次握手的连接。

（3）当 `TCP` 全连接队列不为空后，服务端的 `accept()` 函数，就会从内核中的 `TCP` 全连接队列里拿出一个已经完成连接的 Socket 也就是**已连接套接字**返回给应用程序，后续应用服务器使用这个**已连接套接字**和客户进行通信处理。

连接建立后，客户端和服务端就开始相互传输数据了，双方都可以通过 `read()` 和 `write()` 函数来读写数据。

当数据传输完成后就会调用`close()`函数关闭连接。

以上就是 `TCP` 协议的 `Socket` 程序的调用过程

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/socket01.5fx6tkyx9lk0.png)


> 前面提到的` TCP Socket` 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I/O 时，或者 读写操作发生阻塞时，其他客户端是无法与服务端连接的。

### 服务器单机理论最大能连接多少个客户端，或者说TCP最大连接数是多少

服务器的IP地址和端口号一般是固定不变的，等待客户端的连接请求。

客户端 IP 和 端口是可变的，其理论值计算公式如下:

> 最大 TCP 连接数 = 客户端的 IP 数 * 客户端的端口数

- 对 IPv4 来说，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最 大 TCP 连接数，约为 2 的 48 次方。

- 当然，服务端最大并发 TCP 连接数远不能达到理论上限
  - 首先主要是**文件描述符限制**，Socket 都是文件，所以首先要通过 `ulimit` 配置文件描述符的数目;
  - 另一个是**内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的。


#### 如果服务器的内存只有 2 GB，网卡是千兆的，能支持并发 1 万请求吗

> 并发 1 万请求，也就是经典的 C10K 问题 ，C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。

从硬件资源角度看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 `200KB` 的内存和 `100Kbit` 的网络带宽就可以满足并发 1 万个请求。

不过，要想真正实现 `C10K` 的服务器，要考虑的地方在于服务器的网络 `I/O` 模型，如果模型的效率低，会加重系统开销，从而会离 `C10K` 的目标越来越远。

## I/O 多路复用技术

 `I/O` 多路复用技术就是用一个进程来维护多个 `Socket`。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/IO复用01.4ns3czhz0sk0.png)


一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用。

比较常见的多路复用技术有 `select/poll/epoll`


### select/poll

`select` 将已连接的 `Socket` 都放到一个文件描述符集合，然后调用 `select` 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 `Socket` 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 `Socket`，然后再对其处理。

所以，对于 `select` 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符**集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

`select` 所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 `FD_SETSIZE` 限制， 默认最大值为 `1024`。

`poll` 以链表形式来组织文件描述符，解决了 `select` 的文件描述符个数限制的问题，当然还会受到系统文件描述符限制。

但是 `poll` 和 `select` 并没有太大的本质区别，**都是使用「线性结构」存储进程关注的 `Socket` 集合，因此都需要遍历文件描述符集合来找到可读或可写的 `Socket`，时间复杂度为 `O(n)`，而且也需要在用户态与内核态之间拷贝文件描述符集合**，这种方式随着并发数上来，性能的损耗会呈指数级增长。

### epoll

`epoll` 通过两个方面，很好解决了 `select/poll` 的问题。

- 第一点，`epoll` 在内核里使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的 `socket` 通过 `epoll_ctl()` 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 `O(logn)`，通过对这棵黑红树进行操作，这样就不需要像 `select/poll` 每次操作时都传入整个 `socket` 集合，只需要传入一个待检测的` socket`就可以了，减少了内核和用户空间大量的数据拷贝和内存分配。

- 第二点， `epoll` 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 `socket` 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件发生的文件描述符的个数，不需要像 `select/poll` 那样轮询扫描整个` socket` 集合，大大提高了检测的效率。

从下图你可以看到 `epoll` 相关的接口作用：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/epoll01.58ud4l3nxm00.png)

`epoll` 的方式即使监听的 `Socket` 数量很多的时候，效率不会大幅度降低，能够同时监听的 `Socket` 的数目也非常多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，`epoll` 被称为解决` C10K` 问题的利器。

### 边缘触发和水平触发

`epoll` 支持两种事件触发模式，分别是**边缘触发**（edge-triggered，**ET**）和**水平触发**（level-triggered，**LT**）。

这两个术语还挺抽象的，其实它们的区别还是很好理解的。

- 使用**边缘触发模式**时，当被监控的 `Socket` 描述符上有可读事件发生时，服务器端只会从 `epoll_wait` 中苏醒一次，即使进程没有调用 `read` 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；

- 使用**水平触发模式**时，当被监控的 `Socket` 上有可读事件发生时，服务器端不断地从 `epoll_wait` 中苏醒，直到内核缓冲区数据被 `read` 函数读完才结束，目的是告诉我们有数据需要读取；



一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 `epoll_wait` 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。

`select/poll` 只有水平触发模式，`epoll` **默认的触发模式是水平触发**，但是可以根据应用场景设置为边缘触发模式。




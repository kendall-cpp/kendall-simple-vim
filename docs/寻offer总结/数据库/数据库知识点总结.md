- [数据存储引擎](#数据存储引擎)
  - [MyISAM 和 InnoDB 实现B树索引方式的区别是什么](#myisam-和-innodb-实现b树索引方式的区别是什么)
  - [聚集索引与非聚集索引的区别是什么](#聚集索引与非聚集索引的区别是什么)
- [`MySQL`的索引](#mysql的索引)
  - [为什么要用索引](#为什么要用索引)
  - [覆盖索引是什么](#覆盖索引是什么)
  - [为什么建议使用主键自增的索引](#为什么建议使用主键自增的索引)
  - [创建索引时需要注意什么](#创建索引时需要注意什么)
  - [索引的底层实现（重点）](#索引的底层实现重点)
    - [数据库索引采用B+树而不是B树](#数据库索引采用b树而不是b树)
  - [B树和B+树的区别](#b树和b树的区别)
  - [MySQL索引主要使用的两种数据结构](#mysql索引主要使用的两种数据结构)
  - [索引的实现方式（索引的常见模型）](#索引的实现方式索引的常见模型)
  - [基于主键索引和普通索引的查询有什么区别](#基于主键索引和普通索引的查询有什么区别)
- [MySQL 执行一条查询语句的内部执行过程？](#mysql-执行一条查询语句的内部执行过程)
- [你了解MySQL的内部构造吗，一般可以分为哪两个部分](#你了解mysql的内部构造吗一般可以分为哪两个部分)
- [Mysql的优化](#mysql的优化)
  - [为什么要分库分表](#为什么要分库分表)
    - [如何分表呢，分表的策略](#如何分表呢分表的策略)
  - [一道场景题：假如你所在的公司选择 MySQL 数据库作数据存储，一天五万条以上的增量，预计运维三年，你有哪些优化手段](#一道场景题假如你所在的公司选择-mysql-数据库作数据存储一天五万条以上的增量预计运维三年你有哪些优化手段)
  - [数据库 SQL 语句优化](#数据库-sql-语句优化)
- [事务的四大特性（ACID）](#事务的四大特性acid)
  - [事务的隔离性与隔离级别](#事务的隔离性与隔离级别)
  - [数据库并发事务会带来哪些问题](#数据库并发事务会带来哪些问题)
  - [事务隔离的实现](#事务隔离的实现)
- [听说过视图吗，那游标呢](#听说过视图吗那游标呢)
- [MySQL中为什么要有事务回滚机制 redo log](#mysql中为什么要有事务回滚机制-redo-log)
  - [`redo log`的实现](#redo-log的实现)
  - [数据库如何保证持久性](#数据库如何保证持久性)
  - [binlog 和 redo log 的区别](#binlog-和-redo-log-的区别)
- [说下 InnoDB 中 change buffer](#说下-innodb-中-change-buffer)
  - [什么条件下可以使用 change buffer 呢](#什么条件下可以使用-change-buffer-呢)
  - [如果要在这张表中插入一个新记录，InnoDB 的处理流程是怎样的。](#如果要在这张表中插入一个新记录innodb-的处理流程是怎样的)
- [说一下数据库表锁和行锁吧](#说一下数据库表锁和行锁吧)
- [乐观锁与悲观锁解释一下](#乐观锁与悲观锁解释一下)
  - [乐观锁与悲观锁是怎么实现的](#乐观锁与悲观锁是怎么实现的)
- [MCVV（多版本并发控制）实现机制](#mcvv多版本并发控制实现机制)
- [数据库的范式](#数据库的范式)
- [数据库如何保证一致性](#数据库如何保证一致性)
  - [SQL语法中内连接、自连接、外连接、交叉连接的区别分别是什么](#sql语法中内连接自连接外连接交叉连接的区别分别是什么)
- [什么是最左前缀原则](#什么是最左前缀原则)
- [为什么用 B+ 树做索引而不用哈希表做索引](#为什么用-b-树做索引而不用哈希表做索引)
  - [主键索引和非主键索引有什么区别](#主键索引和非主键索引有什么区别)
  - [主键索引与普通索引哪个快](#主键索引与普通索引哪个快)
  - [为什么建议使用主键自增的索引](#为什么建议使用主键自增的索引-1)

------

## 数据存储引擎

存储引擎是`MYSQL`的核心技术，不同的存储引擎使用不同的存储机制、索引技巧、锁定水平并最终提供不同的功能和能力。常见的引擎分为三种：**InnoDB存储引擎（MYSQL默认的事务性引擎）、MyISAM存储引擎、Memory存储引擎**。

* InnoDB ： `InnoDB`是`mysql`的默认引擎，支持事务和外键，支持容灾恢复。适合更新频繁和多并发的表  行级锁

* MyISAM ： 插入和查询速度比较快，支持大文件，但是不支持事务，适合在`web`和数据仓库场景下使用  表级锁

* MEMORY ： `memory`将表中的数据保存在内存里，适合数据比较小而且频繁访问的场景

### MyISAM 和 InnoDB 实现B树索引方式的区别是什么

MyISAM，B+Tree 叶节点的 data 域存放的是数据记录的地址，在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其 data 域的值，然后以data 域的值为地址读取相应的数据记录，这被称为“非聚簇索引”

InnoDB，其数据文件本身就是索引文件，相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的节点 data 域保存了完整的数据记录，这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引，这被称为“聚簇索引”或者聚集索引，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。

在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；   
在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

> MyIsAM 中 B+ 树的 data 区域存的是数据的地址，检索-->找到 key --> 获取 value（地址） --> 找到数据记录  非聚簇索引

> InnoDB 数据 == 索引，B+ 的 data 保存的是数据记录 --> 索引的 key 是主键（主索引），其他的是辅助索引  聚簇索引      
> 主索引 ==> key ==> 取数据 ，辅助索引 ==> 先走一遍主索引 ==> 长字段不作主键 --> 主索引频繁分裂

### 聚集索引与非聚集索引的区别是什么

- 非聚集索引和聚集索引的区别在于， 通过聚集索引可以查到需要查找的数据， 而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。

- 聚集索引（Innodb）的叶节点就是数据节点，而非聚集索引(MyisAM)的叶节点仍然是索引节点，只不过其包含一个指向对应数据块的指针。

> 聚集索引，可以直接查找数据，    
> 非聚集索引，先找主键值，再通过聚集索引找到数据    
> 表记录的排序和索引的排序是否一致

-----

## `MySQL`的索引

### 为什么要用索引

假设有一张存储了10万个数据（每条数据包含姓名、年龄、身份证号等信息）的表，若没有索引，要想查找姓名为"张三”的身份信息，需要从上到下依次对表中的所有数据进行扫描，找到所有名为张三的数据，这也叫全表查询。

可以看出，全表查询的效率非常低，需要逐条对比，因此就需要通过对每条数据建立索引，从而直接通过索引快速查询到数据信息，大大提高了查询效率。

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义

> 加快查询效率    
> 唯一索引，每一行唯一性    
> 加速表的连接（参考完整性）

### 覆盖索引是什么

如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称 之为“覆盖索引”。

我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次,这样就 会比较慢。覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！

> 索引包含查询字段      
> InnoDB 非主键 主键+列值 回表 慢 索引和列对应，不做回表

### 为什么建议使用主键自增的索引

对于这颗主键索引的树,节点上整行数据分别是 100，200，300，400，500，600

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引01.25xndi6itrog.png)

如果我们插入 `ID = 650` 的一行数据，那么直接在最右边插入就可以了

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引02.571rsw3p9so0.webp)


但是如果插入的是 `ID = 350` 的一行数据，由于 B+ 树是有序的，那么需要将下面的叶子节点进行移动，腾出位置来插入 `ID = 350` 的数据，这样就会比较消耗时间，如果刚好 R4 所在的数据页已经满了，需要进行页分裂操作，这样会更加糟糕。

但是，如果我们的主键是自增的，每次插入的 ID 都会比前面的大，那么我们每次只需要在后面插入就行， 不需要移动位置、分裂等操作，这样可以提高性能。也就是为什么建议使用主键自增的索引。


> 100 ~ 600 如果是插入 650 直接最右插入   
> 插入 350 移动节点，如果这个节点满了，还有分裂   
> 主键自增，ID 比前面大，在后面插入即可，不移动不分裂

### 创建索引时需要注意什么

- **限制表上的索引数目**。对一个存在大量更新操作的表，所建索引的数目一般不要超过3个，最多不要超过5个。索引虽说提高了访问速度，但太多索引会影响数据的更新操作。

- **避免在取值朝一个方向增长的字段**（例如：日期类型的字段）上，建立索引；对复合索引，避免将这种类型的字段放置在最前面。<u>由于字段的取值总是朝一个方向增长，新记录总是存放在索引的最后一个叶页中，从而不断地引起该叶页的访问竞争、新叶页的分配、中间分支页的拆分</u>。此外，如果所建索引是聚集索引，表中数据按照索引的排列顺序存放，所有的插入操作都集中在最后一个数据页上进行，从而引起插入“热点”。

- **删除不再使用**，或者很少被使用的索引。表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再被需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。

> 限制索引数目，影响更新操作      
> 不朝一个方向增长,新页访问竞争，新页分配，支页拆分， 聚集索引==>插入最后进行     
> 删除不再使用，影响更新操作



###  索引的底层实现（重点）

**数据库的索引是使用B+树来实现的**。

> 为什么要用B+树，为什么不用红黑树和B树

B+树是一种特殊的平衡多路树，是 B 树的优化改进版本，它把所有的数据都存放在叶节点上，中间节点保存的是索引。这样一来相对于 B 树来说，减少了数据对中间节点的空间占用，使得中间节点可以存放更多的指针，使得树变得更矮，深度更小，从而减少查询的磁盘 IO 次数，提高查询效率。另一个是由于叶节点之间有指针连接，所以可以进行范围查询，方便区间访问。

B+树查找效率更加稳定，B树有可能在中间节点找到数据，稳定性不够。

#### 数据库索引采用B+树而不是B树

**主要原因**：B+ 树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中**基于范围的查询是非常频繁**的，而 B 树只能中序遍历所有节点，效率太低

而红黑树是二叉树，它的深度相对 B+ 树来说更大，更大的深度意味着查找次数更多，更频繁的磁盘 IO，所以红黑树更适合在内存中进行查找。


> 范围查找频繁，B 树只能中序遍历    
> 红黑树更高，查询次数多


### B树和B+树的区别

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/Bptree.6qj0kx0hs900.png)

这都是由于B+树和B具有不同的存储结构所造成的区别，以一个m阶树为例。

1. **关键字的数量不同**；B+树中分支结点有m个关键字，它的孩子结点也有m个，其关键字只是起到了一个索引的作用，但是B树虽然也有m个子结点，但是其只拥有m-1个关键字。
2. **存储的位置不同**；B+树中的数据都存储在叶子结点上，也就是其所有叶子结点的数据组合起来就是完整的数据，但是B树的数据存储在每一个结点中，并不仅仅存储在叶子结点上。
3. `B+`树的所有叶节点之间有指针连接，所以可以进行范围查询，方便区间访问。
4. **查询不同**；B树在找到具体的数值以后，则结束，而`B+`树则需要通过索引找到叶子结点中的数据才结束，也就是说`B+`树的搜索过程中走了一条从根结点到叶子结点的路径。

B+树优点：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便查询，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来查找，所以B+树更加适合在区间查询的情况。

### MySQL索引主要使用的两种数据结构

**哈希索引**，对于哈希索引来说，底层的数据结构肯定是哈希表，因此在绝大多数需求为**单条记录查询**的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择 BTree 索引

**BTree 索引**，Mysql 的 BTree 索引使用的是 B树 中的 B+Tree，BTree 索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口跟节点开始，依次遍历 各个节点，获取 叶子节点 。

但对于主要的两种存储引擎（ MyISAM 和 InnoDB ）的实现方式是不同的。

> 哈希索引，单条查询较快      
> Btree 索引，使用的是 B+ 树，将数据存入二叉树，然后遍历节点

### 索引的实现方式（索引的常见模型）

常见的有三种，分别是**哈希表**、**有序数组**和**搜索树**。

- **哈希表**

**哈希表**是一种以 键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。

不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。也就是会发生冲突，我们可以使用**链表法**来解决冲突问题。

这种方式往后追加一个节点的速度很快，但是哈希表中的数据不是有序的，所以哈希索引做区间查询的速度是很慢的。

所以，**哈希表这种结构适用于只有等值查询的场景**，比如 Memcached 及其他一些 NoSQL 引擎。

- **有序数组**

**有序数组在等值查询和范围查询场景中的性能就都非常优秀**，仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，**有序数组索引只适用于静态存储引擎**，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。

- **二叉搜索树**

**二叉搜索树**的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。这样如果你要查 查找的时间复杂度是 `O(log(N))`，

当然为了维持 `O(log(N)` 的查询复杂度，需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 `O(log(N))`。

但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。减少磁盘的访问次数。

> 哈希表： 通过 key 找到 value，使用 **链表法** 解决冲突，等值查询的场景，数据不是有序的，范围查找慢。         
> 有序数组： 等值查询和范围查询，插入就麻烦了，一般用于静态存储索引       
> 二叉搜索树： 左子树 `<` 父节点 `<` 右子树，时间复杂度是 `O(log(N))`，少用二叉树，一般用 N 叉树，减少 IO


### 基于主键索引和普通索引的查询有什么区别


![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/InnoDB索引01.5f7e3z4h6z80.png)

假设执行`select id from T where k=5`,从 B+ 树的根节点开始，按层搜索叶子节点，找到这个数据页。

- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

> 普通索引跟唯一索引执行上的区别： 普通索引的等值查询，会继续遍历到第一个不相等的值才会结束，而唯一索引等值查询，命中则结束（性能差距微乎其微）

InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以**页**为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 **16KB**。

- 查询的记录不在页末的时候；当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做一次“查找和判断下一条记录”操作，所以就只需要一次指针寻找和一次计算。

- 查询的记录在页末的时候；那要取下一个记录，就必须读取下一个数据页，（这种情况概率很小）

> 普通索引，找到不相等才结束，唯一索引，查到即结束        
> InnoDB 是以 页 为单位读入内存，每页 16kb ，查询记录不在页末时，查找和取下一条记录，在页末就要取下一数据页（普通索引） 

------ 

## MySQL 执行一条查询语句的内部执行过程？

* 连接器：客户端先通过连接器连接到 MySQL 服务器。
* 缓存：连接器权限验证通过之后，先查询是否有查询缓存，如果有缓存（之前执行过此语句）则直接返回缓存数据，如果没有缓存则进入分析器。
* 分析器：分析器会对查询语句进行语法分析和词法分析，判断 SQL 语法是否正确，如果查询语法错误会直接返回给客户端错误信息，如果语法正确则进入优化器。
* 优化器：优化器是对查询语句进行优化处理，例如一个表里面有多个索引，优化器会判别哪个索引性能更好。
* 执行器：优化器执行完就进入执行器，执行器就开始执行语句进行查询比对了，直到查询到满足条件的所有数据，然后进行返回。

## 你了解MySQL的内部构造吗，一般可以分为哪两个部分

MySQL 的基本架构示意图

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/MySQL逻辑架构.4b5s3h0pgu40.png)

MySQL 可以分为 **Server 层**和**存储引擎层**两部分

Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有**跨存储引擎的功能**都在这一层实现，比如存储过程、触发器、视图等。


存储引擎层负责数据的**存储**和**提取**。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

> 

-----

## Mysql的优化

高频访问：

* 分表分库：将数据库表进行水平拆分，减少表的长度
* 增加缓存： 在web和DB(数据库)之间加上一层缓存层
* 增加数据库的索引：在合适的字段加上索引，解决高频访问的问题

并发优化：

* 主从读写分离：只在主服务器上写，从服务器上读
* 负载均衡集群：通过集群或者分布式的方式解决并发压力


### 为什么要分库分表

数据库出现性能瓶颈。用大白话来说就是数据库快扛不住了。

数据库出现性能瓶颈，对外表现有几个方面：

- **大量请求阻塞**

在高并发场景下，大量请求都需要操作数据库，导致连接数不够了，请求处于阻塞状态。

- **SQL 操作变慢**

如果数据库中存在一张上亿数据量的表，一条 SQL 没有命中索引会全表扫描，这个查询耗时会非常久。

- **存储出现问题**

业务量剧增，单库数据量越来越大，给存储造成巨大压力。

从机器的角度看，性能瓶颈无非就是 CPU、内存、磁盘、网络这些，要解决性能瓶颈最简单粗暴的办法就是提升机器性能，但是通过这种方法成本和收益投入比往往又太高了，不划算，所以重点还是要从软件角度入手

#### 如何分表呢，分表的策略

**水平拆分** 和 **垂直拆分**

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/分表.3mgcs8yrmsg0.png)

- **垂直拆分**

就拿用户表（user）来说，表中有 7 个字段：`id`,`name`,`age`,`sex`,`nickname`,`description`，如果 `nickname` 和 `description` 不常用，我们可以将其拆分为**另外一张表**：用户详细信息表

这样就由一张用户表拆分为了<u>用户基本信息表 + 用户详细信息表</u>

但是从这个角度来看垂直拆分**并没有从根本上解决单表数据量过大的问题**，因此我们还是需要做一次水平拆分。

- **水平拆分**

比如表中有一万条数据，我们拆分为两张表，id 为奇数的：`1，3，5，7……`放在  `user1` 中， id 为偶数的：`2，4，6，8……`放在 `user2` 中，这样的拆分办法就是**水平拆分**了。

> 垂直拆分：基于表或字段划分，表结构不同。

> 水平拆分：基于数据划分，表结构相同，数据不同


### 一道场景题：假如你所在的公司选择 MySQL 数据库作数据存储，一天五万条以上的增量，预计运维三年，你有哪些优化手段

- 设计良好的数据库结构，允许部分数据冗余，尽量避免 join 查询，提高效率。
- 选择合适的表字段数据类型和存储引擎，适当的添加索引。
- MySQL库主从读写分离。
- 找规律分表，减少单表中的数据量提高查询速度。
- 添加缓存机制，比如`Memcached`，`Apc`等。
- 不经常改动的页面，生成静态页面。
- 书写高效率的SQL。比如 `SELECT * FROM TABEL` 改为 `SELECT field_1, field_2, field_3 FROM TABLE`。


### 数据库 SQL 语句优化

1.对查询进行优化，要尽量避免全表扫描，首先应考虑在 `where` 及 `order by `涉及的列上建立索引。

2.应尽量避免在 `where` 子句中对字段进行 `null` 值判断，否则将导致引擎放弃使用索引而进行全表扫描，备注、描述、评论之类的可以设置为 NULL，其他的，最好不要使用`NULL`。

3.应尽量**避免在 where 子句中对字段进行表达式操作**，这将导致引擎放弃使用索引而进行全表扫描。如：

```sql
select id from t where num/2 = 100
```
应改为:
```sql
select id from t where num = 100*2
```
4.任何地方都不要使用 `select * from t` ，用具体的字段列表代替`“*”`，不要返回用不到的任何字段。

5.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。

6.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

[参考这里吧](/数据库/数据库SQL优化总结)

> 加 `where` ,`order by`，不设置 NULL，`where` 不判断 NULL，`where` 不使用表达式，不适用 `select * from`    
> 尽量避免 `join` 查询

-----

## 事务的四大特性（ACID）

1、原子性（Atomicity）： 事务开始后的所有操作要么全部完成，要么全部不完成，不能只完成一部分。事务执行过程中发生错误，会回滚已有操作并恢复到事务开始前的状态。

2、一致性（Consistency）： 事务开始前和结束后，数据库的完整性没有被破坏。比如：A向B转账1000元，A的账户中会减少1000元，而B的账户中会增加1000元。

3、隔离性（Isolation）： 多个事务并发执行时，同一时间只允许一个事务请求同一数据，不同的事务之间不会互相干扰。如：A在从一张银行卡取款的过程中，其他人不能向这张银行卡转账。

4、持久性（Durability）： 事务完成之后，事务对数据库的所有更改应该保存在数据库中，不能回滚。

### 事务的隔离性与隔离级别

### 数据库并发事务会带来哪些问题

当数据库上有多个事务同时执行的时候，就可能出现**脏读**（dirty read）、**不可重复读**（non-repeatable read）、**幻读**（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。

但是隔离得越严实，效率就会越低，因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：**读未提交**（read uncommitted）、**读已提交**（read committed）、**可重复读**（repeatable read）和**串行化**（serializable ）

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。最低级别的隔离，不能解决以上问题
- 读已提交是指，一个事务提交之后，它做的变更才会被其他事务看到。可以避免脏读的发生
- 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。可以避免脏读和不可重复读。
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。可以避免以上所有问题。

用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。

```sql
mysql> create table T(c int) engine=InnoDB;
insert into T(c) values(1);
```

在实现上，数据库里面会创建一个**视图**，访问的时候以视图的逻辑结果为准。

在“读已提交”隔离级别下，这个视图是在每个 SQL 语句**开始执行的时候**创建的。

在“可重复读”隔离级别下，这个视图是在事务**启动时**创建的，整个事务存在期间都用这个视图。

这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，**没有视图概念**；

而“串行化”隔离级别下直接用**加锁**的方式来避免并行访问。

> 关键词：通过视图是实现，读已提交-->SQL语句开始执行的时候创建视图，可重复读-->事务启动时创建视图，读未提交没有视图，串行化通过加锁

我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，一定要将 MySQL 的隔离级别设置为“读提交”。

### 事务隔离的实现

在 MySQL 中，实际上每条记录在更新的时候都会同时**记录一条回滚操作**。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![](https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的**多版本并发控制**（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。

但是回滚日志不可能一直保留，系统会判断，当没有事务需要用到这些 回滚日志 的时候，由 Purge 线程回收。

> 什么时候不需要呢？

当没有比回滚日志更早的读视图 ( read-view )「读视图在事务开启时创建」的时候，这个数据不会再有谁驱使它回滚了，这个回滚日志也就可以删除了。

> 关键词：回滚到前一个状态，后面的视图更改不影响前面的视图，回滚日志在不需要的时候会被 Purge 回收

-------

## 听说过视图吗，那游标呢

**视图**是虚拟的表，与包含数据的表不一样，**视图只包含使用时动态检索数据的查询**；不包含任何 列 或 数据。使用视图可以简化复杂的 SQL 操作，隐藏具体的细节，保护数据；视图创建后，可以使用与表相同的方式利用它们。

视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有`order by` ，对视图再次`order by`将被覆盖。

创建视图：`create view xxx as xxxx`

对于某些视图比如未使用联结子查询分组聚集函数`Distinct Union`等，是可以对其更新的，对视图的更新将对基表进行更新；但是视图主要用于简化检索，保护数据，并不用于更新，而且大部分视图都不可以更新。

**游标**是对查询出来的结果集作为一个单元来有效的处理。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

> 视图是虚拟的表，只包含动态检索查询，简化 sql，保护数据，与表一样使用。        
> 不能被索引，也不能有关联的触发器和默认值    

> 游标，是对查询结果处理，逐条处理数据时使用

## MySQL中为什么要有事务回滚机制 redo log

- 1)能够在发生错误或者用户执行 ROLLBACK 时提供回滚相关的信息 


- 2)在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚

这也就需要回滚日志必须比数据先持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。

> redo log 是 InnoDB 引擎特有的，它主要是用一个**环形链表**来实现的，可以[参考这里☞](/寻offer总结/数据库/数据库专栏学习/数据库专栏笔记?id=更新语句是怎么执行的)

> 错误，回调情况下提供回滚信息    
> 系统崩溃时，可以通过回滚回到未完成的事务    
> 回滚日志比数据先持久化到磁盘

### `redo log`的实现

### 数据库如何保证持久性

> 主要是利用Innodb的redo log。重写日志.

当一条记录更新的时候，`InnoDB` 引擎就会先把记录写到 `redo log`（粉板）里面，并更新内存，这个时候更新就算完成了。同时，`InnoDB` 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/SQL更新流程01.5szqyotr8jw0.png)

`write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。`checkpoint` 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe**。

> 关键词：`redo log`（重做日志）和 `binlog`（归档日志）， 写：`++write pos` 读：`++checkpoint`     
> `InnoDB`--> 内存 --> (空闲时写) 磁盘

### binlog 和 redo log 的区别

`redo log` 是 InnoDB 引擎特有的日志

`binlog`（归档日志) 是server 层的日志


这两种日志有以下三点不同。

- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

> redo log 物理日志，数据做了什么修改，循环写，空间会用完， binlog 逻辑日志，比如：c + 1,追加写，不会覆盖日志

-----

## 说下 InnoDB 中 change buffer 

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。


change buffer 实际上是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

<u>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge</u>。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

change buffer 的 merge 操作，先把 change buffer 的操作更新到内存的数据页中，此操作写到 redo log 中，mysql 未宕机，redo log 写满后需要移动 check point 点时，通过判断内存中数据和磁盘是否一致即是否是脏页来刷新到磁盘中，当 mysql 宕机后没有内存即没有脏页,通过 redo log 来恢复。

显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。


> 记忆：      
> 更新数据页：在内存，更新 ==> 不在内存，缓存 change buffer,下次查询 数据-->内存，操作-->buffer     
> 内存 《 == 》 磁盘    
> merge 操作    操作 --> 内存 -->（未宕机） redo log --> 移动 check point --> 是否是脏数据 --> （宕机）--> redo log 恢复    
> 减少读磁盘，提升速度

### 什么条件下可以使用 change buffer 呢

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。change buffer 用的是 buffer pool 里的内存，因此不能无限增大。

change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

> 唯一索引不能使用 change buffer，内存不能无限大时使用

### 如果要在这张表中插入一个新记录，InnoDB 的处理流程是怎样的。

> 如果要在这张表中插入一个新记录 `(4,400)` 的话，InnoDB 的处理流程是怎样的。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/InnoDB索引01.5f7e3z4h6z80.png)

**第一种情况**是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：
- 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

**第二种情况是**，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：

- 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；

- 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。


将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。


---------

## 说一下数据库表锁和行锁吧

**表锁**

不会出现死锁，发生锁冲突几率高，并发低。

MyISAM 在执行查询语句（`select`）前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁。

MySQL的表级锁有两种模式：表共享读锁和表独占写锁。

读锁会阻塞写，写锁会阻塞读和写


**行锁**

会出现死锁，发生锁冲突几率低，并发高。

在 MySQL 的 InnoDB 引擎支持行锁，与 Oracle 不同，MySQL 的行锁是通过索引加载的，也就是说，行锁是加在索引响应的行上的，要是对应的 SQL 语句没有走索引，则会全表扫描，行锁则无法实现，取而代之的是表锁，此时其它事务无法对当前表进行更新或插入操作。

行锁的实现需要注意：

- 行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。

- 两个事务不能锁同一个索引。

- `insert，delete，update`在事务中都会自动默认加上排它锁。

**行锁的适用场景**：

- A用户消费，server 层先查询该用户的账户余额，若余额足够，则进行后续的扣款操作；这种情况查询的时候应该对该记录进行加锁。

- 否则，B用户在A用户查询后消费前先一步将A用户账号上的钱转走，而此时A用户已经进行了用户余额是否足够的判断，则可能会出现余额已经不足但却扣款成功的情况。

- 为了避免此情况，需要在 A 用户操作该记录的时候进行 for update 加锁

> 读锁不会发生 死锁，select 语句前会自动加死锁，有 共享读锁 和 独占写锁

> 行锁会发生死锁，InnoDB 支持行锁，行锁必须有索引才能实现，否则锁全表，两个事物不能锁同一个索引


## 乐观锁与悲观锁解释一下

一般的数据库都会支持并发操作，在并发操作中为了避免数据冲突，所以需要对数据上锁，乐观锁和悲观锁就是两种不同的上锁方式。

悲观锁假设数据在并发操作中一定会发生冲突，所以在数据开始读取的时候就把数据锁住。而乐观锁则假设数据一般情况下不会发生冲突，所以在数据提交更新的时候，才会检测数据是否有冲突。

悲观锁（Pessimistic Lock） ：适用于**多写**的应用类型

乐观锁（Optimistic Lock）：适用于**多读**的应用类型

[看这个回答](/寻offer总结/操作系统/操作系统02?id=乐观锁与悲观锁)

### 乐观锁与悲观锁是怎么实现的

悲观锁有行级锁和页级锁两种形式。行级锁对正在使用的单条数据进行锁定，事务完成后释放该行数据，而页级锁则对整张表进行锁定，事务正在对该表进行访问的时候不允许其他事务并行访问。

悲观锁要求在整个过程中一直与数据库有一条连接，因为上一个事务完成后才能让下一个事务执行，这个过程是串行的。

乐观锁有三种常用的实现形式：

* 一种是在执行事务时把整个数据都拷贝到应用中，在数据更新提交的时候比较数据库中的数据与新数据，如果两个数据一摸一样则表示没有冲突可以直接提交，如果有冲突就要交给业务逻辑去解决。
* 一种是使用版本号来对数据进行标记，数据每发生一次修改，版本号就增加 1。某条数据在提交的时候，如果数据库中的版本号与自己的一致，就说明数据没有发生修改，否则就认为是过期数据需要处理。
* 最后一种采用时间戳对数据最后修改的时间进行标记。与上一种类似。

> 乐观锁：行锁和页级锁    
> 悲观锁：一直与数据库有连接    
> 乐观锁的实现方式：；整个数据拷贝，版本号，时间戳

## MCVV（多版本并发控制）实现机制

`MCVV`是一种多版本并发控制机制，通过保存数据在某个时间点的快照来实现的。不同的存储引擎的 MCVV 实现是不同的，典型的有乐观（Optimistic）并发控制和悲观（pessimistic）并发控制。

`InnoDB`的`MCVV`，是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的删除时间。这里时间指的并不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务版本号，用来和查询到的每行记录的版本号进行比较。在可重复读(repeatable read)隔离级别下，输入`SELECT`查找语句时，`InnoDB`只查找版本早于当前事务版本的数据行。保存这两个额外的系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作简单，性能好。不足之处就是每行记录都需要额外的存储空间，需要更多的行检查和维护工作。

> 回滚日志视图（快照）,InnoDB 中是两个**隐藏列**实现，一列保存创建时间，一列保存删除时间，智慧查询在事务之前的版本号。

## 数据库的范式


* **第一范式(确保每列保持原子性)**<br>
  第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。

>比如 学生 选课（包括很多课程） 就不符合第一范式

* **第二范式(确保表中的每列都和主键相关)**<br>
  在满足第一范式的前提下，（主要针对联合主键而言）第二范式需要确保数据库表中的每一列都和主键的所有成员直接相关，由整个主键才能唯一确定，而不能只与主键的某一部分相关或者不相关。 

>比如一张学生信息表，由主键（学号）可以唯一确定一个学生的姓名，班级，年龄等信息。但是主键 （学号，班级） 与列 姓名，班主任，教室 就不符合第二范式，因为班主任跟部分主键（班级）是依赖关系

* **第三范式(确保非主键的列没有传递依赖)**<br>
  在满足第二范式的前提下，第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。非主键的列不能确定其他列，列与列之间不能出现传递依赖。

>比如一张学生信息表，主键是（学号）列包括 姓名，班级，班主任 就不符合第三范式，因为非主键的列中 班主任 依赖于 班级

* **BCNF范式（确保主键之间没有传递依赖）**<br>
  主键有可能是由多个属性组合成的复合主键，那么多个主键之间不能有传递依赖。也就是复合主键之间谁也不能决定谁，相互之间没有关系。

----

## 数据库如何保证一致性

分为两个层面来说。

- 从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说 ACID 四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现 AID 三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。

- 从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！

-----
### SQL语法中内连接、自连接、外连接、交叉连接的区别分别是什么

- 内连接：只有两个元素表相匹配的才能在结果集中显示。

- 外连接：左外连接: 左边为驱动表，驱动表的数据全部显示，匹配表的不匹配的不会显示。

- 右外连接:右边为驱动表，驱动表的数据全部显示，匹配表的不匹配的不会显示。全外连接：连接的表中不匹配的数据全部会显示出来。

- 交叉连接：笛卡尔效应，显示的结果是链接表数的乘积。


## 什么是最左前缀原则

例如对于下面这一张表

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/左前缀01.5x44tzpjya40.webp)

如果我们按照 name 字段来建立索引的话，采用B+树的结构，大概的索引结构如下

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/左前缀02.1fyfrwjljwtc.png)

如果我们要进行模糊查找，查找name 以“张"开头的所有人的ID，即 sql 语句为

```sql
select ID from table where name like '张%'
```

由于在 B+ 树结构的索引中，索引项是按照索引定义里面出现的字段顺序排序的，索引在查找的时候，可以快速定位到 ID 为 100 的张一，然后直接向右遍历所有张开头的人，直到条件不满足为止。

也就是说，我们找到第一个满足条件的人之后，直接向右遍历就可以了，由于索引是有序的，所有满足条件的人都会聚集在一起。

而这种定位到最左边，然后向右遍历寻找，就是我们所说的**最左前缀原则**。

## 为什么用 B+ 树做索引而不用哈希表做索引

1、哈希表是把索引字段映射成对应的哈希码然后再存放在对应的位置，这样的话，如果我们要进行模糊查找的话，显然哈希表这种结构是不支持的，只能遍历这个表。而B+树则可以通过最左前缀原则快速找到对应的数据。

2、如果我们要进行范围查找，例如查找ID为`100 ~ 400`的人，哈希表同样不支持，只能遍历全表。

3、索引字段通过哈希映射成哈希码，如果很多字段都刚好映射到相同值的哈希码的话，那么形成的索引结构将会是一条很长的链表，这样的话，查找的时间就会大大增加。


### 主键索引和非主键索引有什么区别
### 主键索引与普通索引哪个快

例如对于下面这个表(其实就是上面的表中增加了一个k字段),且ID是主键

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/主键与非主键01.4fyl1w7q6k60.webp)

主键索引和非主键索引的示意图如下：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/主键与非主键02.258qkc85epkw.webp)

其中R代表一整行的值。

从图中不难看出，**主键索引和非主键索引的区别是**：

- 主键索引的叶子节点存的是**整行数据**。在 InnoDB 里，主键索引也被称为聚簇索引
- 非主键索引的叶子节点内容是**主键的值**。在 InnoDB 里，非主键索引也被称为二级索引

再看看他们在查询上有什么区别：

1、如果查询语句是 `select * from table where ID = 100`,即主键查询的方式，则只需要搜索 ID 这棵 B+树。

2、如果查询语句是 `select * from table where k = 1`，即非主键的查询方式，则先搜索k索引树，得到 ID=100,再到ID索引树搜索一次，这个过程也被称为回表。

> 所以主键索引查询更快


### 为什么建议使用主键自增的索引

对于这颗主键索引的树

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引01.25xndi6itrog.png)

如果我们插入 `ID = 650` 的一行数据，那么直接在最右边插入就可以了

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引02.571rsw3p9so0.webp)


但是如果插入的是 `ID = 350` 的一行数据，由于 B+ 树是有序的，那么需要将下面的叶子节点进行移动，腾出位置来插入 `ID = 350` 的数据，这样就会比较消耗时间，如果刚好 R4 所在的数据页已经满了，需要进行页分裂操作，这样会更加糟糕。

但是，如果我们的主键是自增的，每次插入的 ID 都会比前面的大，那么我们每次只需要在后面插入就行， 不需要移动位置、分裂等操作，这样可以提高性能。也就是为什么建议使用主键自增的索引。

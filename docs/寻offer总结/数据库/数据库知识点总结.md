- [数据存储引擎](#数据存储引擎)
  - [MyISAM 和 InnoDB 实现B树索引方式的区别是什么](#myisam-和-innodb-实现b树索引方式的区别是什么)
  - [聚集索引与非聚集索引的区别是什么](#聚集索引与非聚集索引的区别是什么)
- [`MySQL`的索引](#mysql的索引)
  - [为什么要用索引](#为什么要用索引)
  - [覆盖索引是什么](#覆盖索引是什么)
  - [为什么建议使用主键自增的索引](#为什么建议使用主键自增的索引)
  - [创建索引时需要注意什么](#创建索引时需要注意什么)
  - [索引的底层实现（重点）](#索引的底层实现重点)
    - [数据库索引采用B+树而不是B树](#数据库索引采用b树而不是b树)
  - [B树和B+树的区别](#b树和b树的区别)
  - [MySQL索引主要使用的两种数据结构是](#mysql索引主要使用的两种数据结构是)
  - [索引的实现方式（索引的常见模型）](#索引的实现方式索引的常见模型)
  - [基于主键索引和普通索引的查询有什么区别](#基于主键索引和普通索引的查询有什么区别)
- [MySQL 执行一条查询语句的内部执行过程？](#mysql-执行一条查询语句的内部执行过程)
- [你了解MySQL的内部构造吗，一般可以分为哪两个部分](#你了解mysql的内部构造吗一般可以分为哪两个部分)
- [Mysql的优化](#mysql的优化)
  - [数据库为什么要进行分库和分表呢](#数据库为什么要进行分库和分表呢)
  - [一道场景题：假如你所在的公司选择 MySQL 数据库作数据存储，一天五万条以上的增量，预计运维三年，你有哪些优化手段](#一道场景题假如你所在的公司选择-mysql-数据库作数据存储一天五万条以上的增量预计运维三年你有哪些优化手段)
- [数据库SQL语句优化总结](#数据库sql语句优化总结)
- [事务的四大特性（ACID）](#事务的四大特性acid)
  - [事务的隔离性与隔离级别](#事务的隔离性与隔离级别)
  - [数据库并发事务会带来哪些问题](#数据库并发事务会带来哪些问题)
  - [事务隔离的实现](#事务隔离的实现)
- [听说过视图吗，那游标呢](#听说过视图吗那游标呢)
- [MySQL中为什么要有事务回滚机制 redo log](#mysql中为什么要有事务回滚机制-redo-log)
  - [`redo log`的实现](#redo-log的实现)
  - [数据库如何保证持久性](#数据库如何保证持久性)
  - [binlog 和 redo log 的区别](#binlog-和-redo-log-的区别)
- [说下 InnoDB 中 change buffer](#说下-innodb-中-change-buffer)
  - [什么条件下可以使用 change buffer 呢](#什么条件下可以使用-change-buffer-呢)
  - [如果要在这张表中插入一个新记录，InnoDB 的处理流程是怎样的。](#如果要在这张表中插入一个新记录innodb-的处理流程是怎样的)
- [数据库中的主键、超键、候选键、外键是什么](#数据库中的主键超键候选键外键是什么)
- [说一下数据库表锁和行锁吧](#说一下数据库表锁和行锁吧)
- [乐观锁与悲观锁解释一下](#乐观锁与悲观锁解释一下)
  - [乐观锁与悲观锁是怎么实现的](#乐观锁与悲观锁是怎么实现的)
- [MCVV（多版本并发控制）实现机制](#mcvv多版本并发控制实现机制)
- [数据库的范式](#数据库的范式)
- [数据库如何保证一致性](#数据库如何保证一致性)

------

## 数据存储引擎

存储引擎是`MYSQL`的核心技术，不同的存储引擎使用不同的存储机制、索引技巧、锁定水平并最终提供不同的功能和能力。常见的引擎分为三种：**InnoDB存储引擎（MYSQL默认的事务性引擎）、MyISAM存储引擎、Memory存储引擎**。

* InnoDB ： `InnoDB`是`mysql`的默认引擎，支持事务和外键，支持容灾恢复。适合更新频繁和多并发的表  行级锁

* MyISAM ： 插入和查询速度比较快，支持大文件，但是不支持事务，适合在`web`和数据仓库场景下使用  表级锁

* MEMORY ： `memory`将表中的数据保存在内存里，适合数据比较小而且频繁访问的场景

### MyISAM 和 InnoDB 实现B树索引方式的区别是什么

MyISAM，B+Tree 叶节点的 data 域存放的是数据记录的地址，在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其 data 域的值，然后以data域的值为地址读取相应的数据记录，这被称为“非聚簇索引”

InnoDB，其数据文件本身就是索引文件，相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的节点 data 域保存了完整的数据记录，这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引，这被称为“聚簇索引”或者聚集索引，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。

在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。


### 聚集索引与非聚集索引的区别是什么

- 非聚集索引和聚集索引的区别在于， 通过聚集索引可以查到需要查找的数据， 而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。

- 聚集索引（Innodb）的叶节点就是数据节点，而非聚集索引(MyisAM)的叶节点仍然是索引节点，只不过其包含一个指向对应数据块的指针。

-----

## `MySQL`的索引

### 为什么要用索引

假设有一张存储了10万个数据（每条数据包含姓名、年龄、身份证号等信息）的表，若没有索引，要想查找姓名为"张三”的身份信息，需要从上到下依次对表中的所有数据进行扫描，找到所有名为张三的数据，这也叫全表查询。

可以看出，全表查询的效率非常低，需要逐条对比，因此就需要通过对每条数据建立索引，从而直接通过索引快速查询到数据信息，大大提高了查询效率。

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义

### 覆盖索引是什么

如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称 之为“覆盖索引”。

我们知道在InnoDB存储引 擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次,这样就 会比较慢。覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！

### 为什么建议使用主键自增的索引

对于这颗主键索引的树,节点上整行数据分别是 100，200，300，400，500，600

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引01.25xndi6itrog.png)

如果我们插入 `ID = 650` 的一行数据，那么直接在最右边插入就可以了

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引02.571rsw3p9so0.webp)


但是如果插入的是 `ID = 350` 的一行数据，由于 B+ 树是有序的，那么需要将下面的叶子节点进行移动，腾出位置来插入 `ID = 350` 的数据，这样就会比较消耗时间，如果刚好 R4 所在的数据页已经满了，需要进行页分裂操作，这样会更加糟糕。

但是，如果我们的主键是自增的，每次插入的 ID 都会比前面的大，那么我们每次只需要在后面插入就行， 不需要移动位置、分裂等操作，这样可以提高性能。也就是为什么建议使用主键自增的索引。

### 创建索引时需要注意什么

- 非空字段：应该指定列为NOT NULL，除非你想存储NULL。在 MySQL 中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

- 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

- **索引字段越小越好**：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。唯一、不为空、经常被查询的字段 的字段适合建索引

###  索引的底层实现（重点）

**数据库的索引是使用B+树来实现的**。

> 为什么要用B+树，为什么不用红黑树和B树

B+树是一种特殊的平衡多路树，是 B 树的优化改进版本，它把所有的数据都存放在叶节点上，中间节点保存的是索引。这样一来相对于 B 树来说，减少了数据对中间节点的空间占用，使得中间节点可以存放更多的指针，使得树变得更矮，深度更小，从而减少查询的磁盘IO次数，提高查询效率。另一个是由于叶节点之间有指针连接，所以可以进行范围查询，方便区间访问。

B+树查找效率更加稳定，B树有可能在中间节点找到数据，稳定性不够。

#### 数据库索引采用B+树而不是B树

**主要原因**：B+ 树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而 B 树只能中序遍历所有节点，效率太低

而红黑树是二叉树，它的深度相对 B+ 树来说更大，更大的深度意味着查找次数更多，更频繁的磁盘 IO，所以红黑树更适合在内存中进行查找。


### B树和B+树的区别

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/Bptree.6qj0kx0hs900.png)

这都是由于B+树和B具有不同的存储结构所造成的区别，以一个m阶树为例。

1. **关键字的数量不同**；B+树中分支结点有m个关键字，它的孩子结点也有m个，其关键字只是起到了一个索引的作用，但是B树虽然也有m个子结点，但是其只拥有m-1个关键字。
2. **存储的位置不同**；B+树中的数据都存储在叶子结点上，也就是其所有叶子结点的数据组合起来就是完整的数据，但是B树的数据存储在每一个结点中，并不仅仅存储在叶子结点上。
3. `B+`树的所有叶节点之间有指针连接，所以可以进行范围查询，方便区间访问。
4. **查询不同**；B树在找到具体的数值以后，则结束，而`B+`树则需要通过索引找到叶子结点中的数据才结束，也就是说`B+`树的搜索过程中走了一条从根结点到叶子结点的路径。

B+树优点：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便查询，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来查找，所以B+树更加适合在区间查询的情况。

### MySQL索引主要使用的两种数据结构是

哈希索引，对于哈希索引来说，底层的数据结构肯定是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引

BTree索引，Mysql的BTree索引使用的是B树中的B+Tree，BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。

但对于主要的两种存储引擎（MyISAM和InnoDB）的实现方式是不同的。

### 索引的实现方式（索引的常见模型）

常见的有三种，分别是**哈希表**、**有序数组**和**搜索树**。

- **哈希表**

**哈希表**是一种以 键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。

不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。也就是会发生冲突，我们可以使用**链表法**来解决冲突问题。

这种方式往后追加一个节点的速度很快，但是哈希表中的数据不是有序的，所以哈希索引做区间查询的速度是很慢的。

所以，**哈希表这种结构适用于只有等值查询的场景**，比如 Memcached 及其他一些 NoSQL 引擎。

- **有序数组**

**有序数组在等值查询和范围查询场景中的性能就都非常优秀**，仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，**有序数组索引只适用于静态存储引擎**，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。

- **二叉搜索树**

**二叉搜索树**的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。这样如果你要查 查找的时间复杂度是 `O(log(N))`，

当然为了维持 `O(log(N))` 的查询复杂度，需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 `O(log(N))`。

但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。减少磁盘的访问次数。

### 基于主键索引和普通索引的查询有什么区别


![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/InnoDB索引01.5f7e3z4h6z80.png)

假设执行`select id from T where k=5`,从 B+ 树的根节点开始，按层搜索叶子节点，找到这个数据页。

- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

> 普通索引跟唯一索引执行上的区别： 普通索引的等值查询，会继续遍历到第一个不相等的值才会结束，而唯一索引等值查询，命中则结束（性能差距微乎其微）

InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以**页**为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。

- 查询的记录不在页末的时候；当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。

- 查询的记录在页末的时候；那要取下一个记录，就必须读取下一个数据页，（这种情况概率很小）


------ 

## MySQL 执行一条查询语句的内部执行过程？

* 连接器：客户端先通过连接器连接到 MySQL 服务器。
* 缓存：连接器权限验证通过之后，先查询是否有查询缓存，如果有缓存（之前执行过此语句）则直接返回缓存数据，如果没有缓存则进入分析器。
* 分析器：分析器会对查询语句进行语法分析和词法分析，判断 SQL 语法是否正确，如果查询语法错误会直接返回给客户端错误信息，如果语法正确则进入优化器。
* 优化器：优化器是对查询语句进行优化处理，例如一个表里面有多个索引，优化器会判别哪个索引性能更好。
* 执行器：优化器执行完就进入执行器，执行器就开始执行语句进行查询比对了，直到查询到满足条件的所有数据，然后进行返回。

## 你了解MySQL的内部构造吗，一般可以分为哪两个部分

MySQL 的基本架构示意图

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/MySQL逻辑架构.4b5s3h0pgu40.png)

MySQL 可以分为 **Server 层**和**存储引擎层**两部分

Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有**跨存储引擎的功能**都在这一层实现，比如存储过程、触发器、视图等。


存储引擎层负责数据的**存储**和**提取**。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

-----

## Mysql的优化

高频访问：

* 分表分库：将数据库表进行水平拆分，减少表的长度
* 增加缓存： 在web和DB(数据库)之间加上一层缓存层
* 增加数据库的索引：在合适的字段加上索引，解决高频访问的问题

并发优化：

* 主从读写分离：只在主服务器上写，从服务器上读
* 负载均衡集群：通过集群或者分布式的方式解决并发压力

### 数据库为什么要进行分库和分表呢

分库与分表的目的在于，减小数据库的单库单表负担，提高查询性能，缩短查询时间。

**通过分表**，可以减少数据库的单表负担，将压力分散到不同的表上，同时因为不同的表上的数据量少了，起到提高查询性能，缩短查询时间的作用，此外，可以很大的缓解表锁的问题。分表策略可以归纳为垂直拆分和水平拆分:

**水平分表**：取模分表就属于随机分表，而时间维度分表则属于连续分表。如何设计好垂直拆分，我的建议：将不常用的字段单独拆分到另外一张扩展表. 将大文本的字段单独拆分到另外一张扩展表, 将不经常修改的字段放在同一张表中，将经常改变的字段放在另一张表中。对于海量用户场景，可以考虑取模分表，数据相对比较均匀，不容易出现热点和并发访问的瓶颈。

**库内分表**，仅仅是解决了单表数据过大的问题，但并没有把单表的数据分散到不同的物理机上，因此并不能减轻 MySQL 服务器的压力，仍然存在同一个物理机上的资源竞争和瓶颈，包括 CPU、内存、磁盘 IO、网络带宽等。

**分库与分表带来的分布式困境与应对之策**数据迁移与扩容问题----一般做法是通过程序先读出数据，然后按照指定的分表策略再将数据写入到各个分表中。分页与排序问题----需要在不同的分表中将数据进行排序并返回，并将不同分表返回的结果集进行汇总和再次排序，最后再返回给用户。

### 一道场景题：假如你所在的公司选择 MySQL 数据库作数据存储，一天五万条以上的增量，预计运维三年，你有哪些优化手段

- 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。
- 选择合适的表字段数据类型和存储引擎，适当的添加索引。
- MySQL库主从读写分离。
- 找规律分表，减少单表中的数据量提高查询速度。
- 添加缓存机制，比如`Memcached`，`Apc`等。
- 不经常改动的页面，生成静态页面。
- 书写高效率的SQL。比如 `SELECT * FROM TABEL` 改为 `SELECT field_1, field_2, field_3 FROM TABLE`。


## 数据库SQL语句优化总结

1.对查询进行优化，要尽量避免全表扫描，首先应考虑在 `where` 及 `order by `涉及的列上建立索引。

2.应尽量避免在 `where` 子句中对字段进行 `null` 值判断，否则将导致引擎放弃使用索引而进行全表扫描，备注、描述、评论之类的可以设置为 NULL，其他的，最好不要使用`NULL`。

3.应尽量**避免在 where 子句中对字段进行表达式操作**，这将导致引擎放弃使用索引而进行全表扫描。如：

```sql
select id from t where num/2 = 100
```
应改为:
```sql
select id from t where num = 100*2
```
4.任何地方都不要使用 `select * from t` ，用具体的字段列表代替`“*”`，不要返回用不到的任何字段。

5.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。

6.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

[参考这里吧](/数据库/数据库SQL优化总结)

-----

## 事务的四大特性（ACID）

1、原子性（Atomicity）： 事务开始后的所有操作要么全部完成，要么全部不完成，不能只完成一部分。事务执行过程中发生错误，会回滚已有操作并恢复到事务开始前的状态。

2、一致性（Consistency）： 事务开始前和结束后，数据库的完整性没有被破坏。比如：A向B转账1000元，A的账户中会减少1000元，而B的账户中会增加1000元。

3、隔离性（Isolation）： 多个事务并发执行时，同一时间只允许一个事务请求同一数据，不同的事务之间不会互相干扰。如：A在从一张银行卡取款的过程中，其他人不能向这张银行卡转账。

4、持久性（Durability）： 事务完成之后，事务对数据库的所有更改应该保存在数据库中，不能回滚。

### 事务的隔离性与隔离级别

### 数据库并发事务会带来哪些问题

当数据库上有多个事务同时执行的时候，就可能出现**脏读**（dirty read）、**不可重复读**（non-repeatable read）、**幻读**（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。

但是隔离得越严实，效率就会越低，因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：**读未提交**（read uncommitted）、**读已提交**（read committed）、**可重复读**（repeatable read）和**串行化**（serializable ）

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。最低级别的隔离，不能解决以上问题
- 读已提交是指，一个事务提交之后，它做的变更才会被其他事务看到。可以避免脏读的发生
- 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。可以避免脏读和不可重复读。
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。可以避免以上所有问题。

用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。

```sql
mysql> create table T(c int) engine=InnoDB;
insert into T(c) values(1);
```

在实现上，数据库里面会创建一个**视图**，访问的时候以视图的逻辑结果为准。

在“读已提交”隔离级别下，这个视图是在每个 SQL 语句**开始执行的时候**创建的。

在“可重复读”隔离级别下，这个视图是在事务**启动时**创建的，整个事务存在期间都用这个视图。

这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，**没有视图概念**；

而“串行化”隔离级别下直接用**加锁**的方式来避免并行访问。

> 关键词：通过视图是实现，读已提交-->SQL语句开始执行的时候创建视图，可重复读-->事务启动时创建视图，读未提交没有视图，串行化通过加锁

我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，一定要将 MySQL 的隔离级别设置为“读提交”。

### 事务隔离的实现

在 MySQL 中，实际上每条记录在更新的时候都会同时**记录一条回滚操作**。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![](https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的**多版本并发控制**（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。

但是回滚日志不可能一直保留，系统会判断，当没有事务需要用到这些 回滚日志 的时候，由 Purge 线程回收。

> 什么时候不需要呢？

当没有比回滚日志更早的读视图 ( read-view )「读视图在事务开启时创建」的时候，这个数据不会再有谁驱使它回滚了，这个回滚日志也就可以删除了。

> 关键词：回滚到前一个状态，后面的视图更改不影响前面的视图，回滚日志在不需要的时候会被 Purge 回收

-------

## 听说过视图吗，那游标呢

**视图**是虚拟的表，与包含数据的表不一样，视图只包含使用时动态检索数据的查询；不包含任何列或数据。使用视图可以简化复杂的 sql 操作，隐藏具体的细节，保护数据；视图创建后，可以使用与表相同的方式利用它们。

视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有`order by` 则对视图再次order by将被覆盖。

创建视图：`create view xxx as xxxx`

对于某些视图比如未使用联结子查询分组聚集函数Distinct Union等，是可以对其更新的，对视图的更新将对基表进行更新；但是视图主要用于简化检索，保护数据，并不用于更新，而且大部分视图都不可以更新。

**游标**是对查询出来的结果集作为一个单元来有效的处理。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

## MySQL中为什么要有事务回滚机制 redo log

- 1)能够在发生错误或者用户执行 ROLLBACK 时提供回滚相关的信息 


- 2)在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚

这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。

> redo log 是 InnoDB 引擎特有的，它主要是用一个环形链表来实现的

### `redo log`的实现

### 数据库如何保证持久性

> 主要是利用Innodb的redo log。重写日志.

当一条记录更新的时候，`InnoDB` 引擎就会先把记录写到 `redo log`（粉板）里面，并更新内存，这个时候更新就算完成了。同时，`InnoDB` 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/SQL更新流程01.5szqyotr8jw0.png)

`write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。`checkpoint` 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe**。

> 关键词：`redo log`（重做日志）和 `binlog`（归档日志）， 写：`++write pos` 读：`++checkpoint`     
> `InnoDB`--> 内存 --> (空闲时写) 磁盘

### binlog 和 redo log 的区别

`redo log` 是 InnoDB 引擎特有的日志

`binlog`（归档日志) 是server 层的日志


这两种日志有以下三点不同。

- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

> redo log 物理日志，数据做了什么修改，循环写，空间会用完， binlog 逻辑日志，比如：c + 1,追加写，不会覆盖日志

-----

## 说下 InnoDB 中 change buffer 

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。


change buffer 实际上是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

change buffer 的 merge 操作，先把 change buffer 的操作更新到内存的数据页中，此操作写到 redo log 中，mysql 未宕机，redo log 写满后需要移动check point点时，通过判断内存中数据和磁盘是否一致即是否是脏页来刷新到磁盘中，当 mysql 宕机后没有内存即没有脏页,通过redo log来恢复。

显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。

> change buffer 的 merge 操作，先把 change buffer 的操作更新到内存的数据页中，此操作写到 redo log 中，mysql未宕机，redo log写满后需要移动 check point 点时，通过判断内存中数据和磁盘是否一致即是否是脏页来刷新到磁盘中，当mysql 宕机后没有内存即没有脏页,通过 redo log 来恢复。

### 什么条件下可以使用 change buffer 呢

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。change buffer 用的是 buffer pool 里的内存，因此不能无限增大。

change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

### 如果要在这张表中插入一个新记录，InnoDB 的处理流程是怎样的。

> 如果要在这张表中插入一个新记录 `(4,400)` 的话，InnoDB 的处理流程是怎样的。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/InnoDB索引01.5f7e3z4h6z80.png)

**第一种情况**是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：
- 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

**第二种情况是**，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：

- 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；

- 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。


将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

------------

## 数据库中的主键、超键、候选键、外键是什么

**超键**：在关系中能唯一标识元组的属性集称为关系模式的超键

**候选键**：不含有多余属性的超键称为候选键。也就是在候选键中，若再删除属性，就不是键了！

**主键**：用户选作元组标识的一个候选键程序主键

**外键**：如果关系模式R中属性K是其它模式的主键，那么k在模式R中称为外键。

> **主键为候选键的子集，候选键为超键的子集，而外键的确定是相对于主键的**。


![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/主键各种键.68xsl7ugibg0.png)

- 超键：于是我们从例子中可以发现 学号是标识学生实体的唯一标识。那么该元组的超键就为学号。除此之外我们还可以把它跟其他属性组合起来，比如：(学号，性别)，(学号，年龄)
- 候选键：根据例子可知，学号是一个可以唯一标识元组的唯一标识，因此学号是一个候选键，实际上，候选键是超键的子集，比如 （学号，年龄）是超键，但是它不是候选键。因为它还有了额外的属性。
- 主键：简单的说，例子中的元组的候选键为学号，但是我们选定他作为该元组的唯一标识，那么学号就为主键。
- 外键是相对于主键的，比如在学生记录里，主键为学号，在成绩单表中也有学号字段，因此学号为成绩单表的外键，为学生表的主键。

---------

## 说一下数据库表锁和行锁吧

**表锁**

不会出现死锁，发生锁冲突几率高，并发低。

MyISAM在执行查询语句（select）前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁。

MySQL的表级锁有两种模式：表共享读锁和表独占写锁。

读锁会阻塞写，写锁会阻塞读和写

对MyISAM表的读操作，不会阻塞其它进程对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。
对MyISAM表的写操作，会阻塞其它进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。
MyISAM不适合做写为主表的引擎，因为写锁后，其它线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。

**行锁**

会出现死锁，发生锁冲突几率低，并发高。

在MySQL的InnoDB引擎支持行锁，与Oracle不同，MySQL的行锁是通过索引加载的，也就是说，行锁是加在索引响应的行上的，要是对应的SQL语句没有走索引，则会全表扫描，行锁则无法实现，取而代之的是表锁，此时其它事务无法对当前表进行更新或插入操作。

行锁的实现需要注意：

- 行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。

- 两个事务不能锁同一个索引。

- `insert，delete，update`在事务中都会自动默认加上排它锁。

**行锁的适用场景**：

- A用户消费，service层先查询该用户的账户余额，若余额足够，则进行后续的扣款操作；这种情况查询的时候应该对该记录进行加锁。

- 否则，B用户在A用户查询后消费前先一步将A用户账号上的钱转走，而此时A用户已经进行了用户余额是否足够的判断，则可能会出现余额已经不足但却扣款成功的情况。

- 为了避免此情况，需要在A用户操作该记录的时候进行for update加锁

## 乐观锁与悲观锁解释一下

一般的数据库都会支持并发操作，在并发操作中为了避免数据冲突，所以需要对数据上锁，乐观锁和悲观锁就是两种不同的上锁方式。

悲观锁假设数据在并发操作中一定会发生冲突，所以在数据开始读取的时候就把数据锁住。而乐观锁则假设数据一般情况下不会发生冲突，所以在数据提交更新的时候，才会检测数据是否有冲突。

悲观锁（Pessimistic Lock） ：适用于多写的应用类型

乐观锁（Optimistic Lock）：适用于多读的应用类型

[看这个回答](/寻offer总结/操作系统/操作系统02?id=乐观锁与悲观锁)

### 乐观锁与悲观锁是怎么实现的

悲观锁有行级锁和页级锁两种形式。行级锁对正在使用的单条数据进行锁定，事务完成后释放该行数据，而页级锁则对整张表进行锁定，事务正在对该表进行访问的时候不允许其他事务并行访问。

悲观锁要求在整个过程中一直与数据库有一条连接，因为上一个事务完成后才能让下一个事务执行，这个过程是串行的。

乐观锁有三种常用的实现形式：

* 一种是在执行事务时把整个数据都拷贝到应用中，在数据更新提交的时候比较数据库中的数据与新数据，如果两个数据一摸一样则表示没有冲突可以直接提交，如果有冲突就要交给业务逻辑去解决。
* 一种是使用版本号来对数据进行标记，数据每发生一次修改，版本号就增加1。某条数据在提交的时候，如果数据库中的版本号与自己的一致，就说明数据没有发生修改，否则就认为是过期数据需要处理。
* 最后一种采用时间戳对数据最后修改的时间进行标记。与上一种类似。


## MCVV（多版本并发控制）实现机制

`MCVV`是一种多版本并发控制机制，通过保存数据在某个时间点的快照来实现的。不同的存储引擎的MCVV实现是不同的，典型的有乐观（Optimistic）并发控制和悲观（pessimistic）并发控制。

`InnoDB`的`MCVV`，是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的删除时间。这里时间指的并不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务版本号，用来和查询到的每行记录的版本号进行比较。在可重复读(repeatable read)隔离级别下，输入`SELECT`查找语句时，`InnoDB`只查找版本早于当前事务版本的数据行。保存这两个额外的系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作简单，性能好。不足之处就是每行记录都需要额外的存储空间，需要更多的行检查和维护工作。

## 数据库的范式


* **第一范式(确保每列保持原子性)**<br>
  第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。

>比如 学生 选课（包括很多课程） 就不符合第一范式

* **第二范式(确保表中的每列都和主键相关)**<br>
  在满足第一范式的前提下，（主要针对联合主键而言）第二范式需要确保数据库表中的每一列都和主键的所有成员直接相关，由整个主键才能唯一确定，而不能只与主键的某一部分相关或者不相关。 

>比如一张学生信息表，由主键（学号）可以唯一确定一个学生的姓名，班级，年龄等信息。但是主键 （学号，班级） 与列 姓名，班主任，教室 就不符合第二范式，因为班主任跟部分主键（班级）是依赖关系

* **第三范式(确保非主键的列没有传递依赖)**<br>
  在满足第二范式的前提下，第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。非主键的列不能确定其他列，列与列之间不能出现传递依赖。

>比如一张学生信息表，主键是（学号）列包括 姓名，班级，班主任 就不符合第三范式，因为非主键的列中 班主任 依赖于 班级

* **BCNF范式（确保主键之间没有传递依赖）**<br>
  主键有可能是由多个属性组合成的复合主键，那么多个主键之间不能有传递依赖。也就是复合主键之间谁也不能决定谁，相互之间没有关系。

----

## 数据库如何保证一致性

分为两个层面来说。

- 从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，
  
- 原子性无法保证，显然一致性也无法保证。
从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！


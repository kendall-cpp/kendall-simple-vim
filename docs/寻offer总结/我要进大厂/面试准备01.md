> 每天学习一点面试

------

- [20210511](#20210511)
  - [堆和栈的区别](#堆和栈的区别)
  - [指针和引用的区别](#指针和引用的区别)
  - [TCP三次握手四次挥手，timewait多了怎么解决](#tcp三次握手四次挥手timewait多了怎么解决)
    - [三次握手](#三次握手)
    - [四次挥手](#四次挥手)
    - [Time_wait状态的链接过多会怎样](#time_wait状态的链接过多会怎样)
    - [如何优化 TIME_WAIT](#如何优化-time_wait)
- [20210512](#20210512)
  - [同步io和异步io](#同步io和异步io)
  - [优化数据库](#优化数据库)
  - [B树和B+树的区别](#b树和b树的区别)
  - [长字符串找短字符串，可以使用hash吗](#长字符串找短字符串可以使用hash吗)
  - [各种排序的思路冒泡-快排-归并](#各种排序的思路冒泡-快排-归并)
  - [TCP与UDP的区别](#tcp与udp的区别)
    - [TCP 包过大会怎样](#tcp-包过大会怎样)
- [20200514](#20200514)
  - [MySQL存储引擎](#mysql存储引擎)
  - [大小端怎么判断](#大小端怎么判断)
  - [`void*` 可以直接输出值吗](#void-可以直接输出值吗)
  - [timewait状态多久，为什么要有](#timewait状态多久为什么要有)
  - [B+树一个节点有多大？一千万条数据，B+树多高？](#b树一个节点有多大一千万条数据b树多高)
  - [**海量数据问题**](#海量数据问题)
    - [1亿数据数组找最大1万个](#1亿数据数组找最大1万个)
  - [如何冲100亿 URL 中找出相同的 URL](#如何冲100亿-url-中找出相同的-url)
    - [100万url找到出现频率最高的100个](#100万url找到出现频率最高的100个)
  - [STL中hashTable的实现](#stl中hashtable的实现)
- [20150516](#20150516)
  - [五层协议，每层都有哪些协议](#五层协议每层都有哪些协议)
  - [TCP怎么保证可靠传输的](#tcp怎么保证可靠传输的)
  - [说一下`TCP`怎么进行拥塞控制的？](#说一下tcp怎么进行拥塞控制的)
  - [静态多态和动态多态](#静态多态和动态多态)
  - [C++虚函数相关，虚函数的实现原理](#c虚函数相关虚函数的实现原理)
  - [虚函数表是如何实现动态绑定的](#虚函数表是如何实现动态绑定的)
  - [多态时候基类的sizeof，子类的sizeof](#多态时候基类的sizeof子类的sizeof)
  - [为什么成员函数不占用类的空间](#为什么成员函数不占用类的空间)
- [好未来实习面试准备](#好未来实习面试准备)
  - [对好未来产品的认识](#对好未来产品的认识)
  - [设计一个在线教育平台需要有哪些功能需求](#设计一个在线教育平台需要有哪些功能需求)
  - [非阻塞connect实现](#非阻塞connect实现)
  - [程序编译过程](#程序编译过程)
  - [静态库和动态库](#静态库和动态库)
    - [静态库](#静态库)
    - [共享库/动态库](#共享库动态库)
  - [写一个不能复制的类](#写一个不能复制的类)
  - [说一下`C++`里的智能指针](#说一下c里的智能指针)
    - [智能指针出现循环引用怎么解决？](#智能指针出现循环引用怎么解决)
  - [select和epoll的区别](#select和epoll的区别)
  - [https建立的过程](#https建立的过程)
  - [DNS解析](#dns解析)
    - [`DNS`解析过程](#dns解析过程)
  - [什么时候用多进程，什么时候用多线程](#什么时候用多进程什么时候用多线程)
  - [一个进程都分为那些内存空间](#一个进程都分为那些内存空间)
- [腾讯相关面经20210519](#腾讯相关面经20210519)
  - [C++内存分区](#c内存分区)
  - [`new/delete` 与 `malloc/free` 的异同](#newdelete-与-mallocfree-的异同)
  - [C++如何检测内存泄露](#c如何检测内存泄露)
  - [STL几大部件](#stl几大部件)
  - [map、set是怎么实现的,为什么](#mapset是怎么实现的为什么)
  - [发送缓冲区](#发送缓冲区)
  - [树的遍历和应用场景](#树的遍历和应用场景)
  - [函数栈的大小查看，怎么更改大小](#函数栈的大小查看怎么更改大小)
  - [UDP怎么实现可靠传输](#udp怎么实现可靠传输)
- [20210520](#20210520)
  - [http和https的区别](#http和https的区别)
  - [拥塞控制和流量控制的区别](#拥塞控制和流量控制的区别)
  - [流量控制的介绍，采用滑动窗口会有什么问题](#流量控制的介绍采用滑动窗口会有什么问题)
  - [TCP 滑动窗口协议](#tcp-滑动窗口协议)
  - [线程安全问题](#线程安全问题)
    - [为什么会有线程安全问题](#为什么会有线程安全问题)
    - [如何解决多线程之间线程安全问题](#如何解决多线程之间线程安全问题)
  - [进程_线程的互斥与同步的实现和使用](#进程_线程的互斥与同步的实现和使用)
    - [进程同步方式](#进程同步方式)
    - [线程同步的方式](#线程同步的方式)
  - [二叉搜索树找第k个数](#二叉搜索树找第k个数)
- [20210521](#20210521)
  - [Linux常用命令，怎么查看内存和端口](#linux常用命令怎么查看内存和端口)
  - [数组和链表的内存存储和插入](#数组和链表的内存存储和插入)
  - [unordered_map 和 map 的底层实现，以及使用场景如何选择](#unordered_map-和-map-的底层实现以及使用场景如何选择)
  - [`#include`时`“”`和`<>`的区别](#include时和的区别)
  - [构造函数和析构函数可以调用虚函数吗，为什么](#构造函数和析构函数可以调用虚函数吗为什么)
    - [构造函数为什么一般不定义为虚函数](#构造函数为什么一般不定义为虚函数)
    - [基类的析构函数为什么一般写成虚函数](#基类的析构函数为什么一般写成虚函数)
    - [构造函数或者析构函数中调用虚函数会怎样](#构造函数或者析构函数中调用虚函数会怎样)
  - [介绍一下HTTP/1 HTTP/2 HTTP/3的发展](#介绍一下http1-http2-http3的发展)
  - [纯虚函数](#纯虚函数)
    - [虚函数和纯虚函数区别](#虚函数和纯虚函数区别)
  - [STL中vector的实现](#stl中vector的实现)
    - [vector扩容](#vector扩容)
    - [vector频繁对vector调用push_back对性能的影响和原因](#vector频繁对vector调用push_back对性能的影响和原因)
    - [C++中vector和list的区别](#c中vector和list的区别)
  - [内存页面置换算法](#内存页面置换算法)
    - [什么是缺页异常,缺页中断](#什么是缺页异常缺页中断)
    - [常见的页面置换算法](#常见的页面置换算法)
- [好未来实习一面](#好未来实习一面)
  - [什么是最左前缀原则](#什么是最左前缀原则)
  - [为什么用 B+ 树做索引而不用哈希表做索引](#为什么用-b-树做索引而不用哈希表做索引)
  - [主键索引和非主键索引有什么区别](#主键索引和非主键索引有什么区别)
  - [主键索引与普通索引哪个快](#主键索引与普通索引哪个快)
  - [为什么建议使用主键自增的索引](#为什么建议使用主键自增的索引)
- [好未来实习二面](#好未来实习二面)
  - [`unordered_map`和`map`的区别](#unordered_map和map的区别)
  - [内存泄漏的定义，什么时候会造成内存泄漏](#内存泄漏的定义什么时候会造成内存泄漏)
  - [内存泄漏避免方法](#内存泄漏避免方法)
    - [怎么排查](#怎么排查)
  - [数组越界问题，怎么解决](#数组越界问题怎么解决)
- [上海统信一面](#上海统信一面)
  - [面向对象的三大特性是：封装，继承和多态。](#面向对象的三大特性是封装继承和多态)
    - [面向对象的本质是什么，面向过程是怎么样的](#面向对象的本质是什么面向过程是怎么样的)
  - [局部变量和静态变量，局部变量的生命周期](#局部变量和静态变量局部变量的生命周期)
  - [static 关键字](#static-关键字)
  - [static 修饰全局变量和普通全局变量的区别](#static-修饰全局变量和普通全局变量的区别)
  - [什么是抽象类](#什么是抽象类)
  - [虚函数和纯虚函数区别](#虚函数和纯虚函数区别-1)
  - [ARP协议说一下](#arp协议说一下)
- [好未来 IOS 中台](#好未来-ios-中台)
  - [介绍一下堆](#介绍一下堆)
  - [单线程下会不会发生死锁](#单线程下会不会发生死锁)
- [抖音后端21届校招](#抖音后端21届校招)
  - [讲了一下线程库（mutex, conditional variable, thread）的C++实现](#讲了一下线程库mutex-conditional-variable-thread的c实现)
  - [C++中的多线程](#c中的多线程)
  - [设计线程池](#设计线程池)
  - [单线程处理多个请求的方式](#单线程处理多个请求的方式)
  - [C语言为什么不能进行函数重载](#c语言为什么不能进行函数重载)
  - [野指针和悬空指针](#野指针和悬空指针)

## 20210511

-----

### 堆和栈的区别

* 栈，栈由系统自动分配，存储的是一些临时变量，包括局部变量，返回值，参数，返回地址等等。栈空间是有存储大小的，如果超过这个大小将会出现栈溢出。
* 堆，是一个比较大的内存空间，主要用来动态分配内存，这一部分通常由程序员进行分配和释放。如果在程序结束的时候还未释放，就会被操作系统回收。
* 堆的生长空间向高地址生长的，地址越来越大，栈的生长空间向低地址生长的，地址越来越小
* 栈相对于堆来说会快一点，因为操作系统会在底层对栈提供支持，会分配专门的寄存器存放栈的地址，栈的入栈出栈操作也十分简单，并且有专门的指令执行，所以栈的效率比较高也比较快。而堆的操作是由`C/C++`函数库提供的，堆在分配和释放时都要调用函数（`malloc,free`)。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。

### 指针和引用的区别

* 指针是一个新的变量，指向另一个变量的地址，我们可以通过访问这个地址来修改另一个变量；而引用是一个别名，对引用的操作就是对变量的本身进行操作
* 指针可以有多级，引用只有一级
* 传参的时候，使用指针的话需要解引用才能对参数进行修改，而使用引用可以直接对参数进行修改
* 指针的大小一般是4个字节，引用的大小取决于被引用对象的大小
* 指针可以为空，引用不可以。
* 引用一旦进行初始化之后，不会再改变其指向；但指针可以

### TCP三次握手四次挥手，timewait多了怎么解决

#### 三次握手

- 第一次握手：

客户端要向服务端发起连接请求，首先客户端随机生成一个起始序列号`ISN`(比如是`100`)，那客户端向服务端发送的报文段包含同步序号`SYN`标志位(也就是`SYN=1`)，序列号`seq=100`。

这时候`client`处于同步状态`SYN_SENT`。也就是可以建立连接。服务端处于监听状态`LISTEN`。

- 第二次握手

服务端收到客户端发过来的报文后，发现同步序号`SYN=1`，知道这是一个连接请求，于是将客户端的起始序列号`100`存起来，并且随机生成一个服务端的起始序列号(比如是`300`)。然后给客户端回复一段报文，回复报文包含`SYN`和`ACK`标志(也就是`SYN=1`,`ACK=1`)、序列号`seq=300`、确认号`ack=101`(*客户端发过来的序列号+1*)。

  这个时候服务端处于`SYN_RECV`同步接收状态。

- 第三次握手

客户端收到服务端的回复后发现`ACK=1`并且`ack=101`,于是知道服务端已经收到了序列号为`100`的那段报文；同时发现`SYN=1`，知道了服务端同意了这次连接，于是就将服务端的序列号`300`给存下来。然后客户端再回复一段报文给服务端，报文包含`ACK`标志位(`ACK=1`)、`ack=301`(*服务端序列号+1*)、`seq=101`(第一次握手时发送报文是占据一个序列号的，所以这次`seq`就从`101`开始，需要注意的是不携带数据的`ACK`报文是不占据序列号的，所以后面第一次正式发送数据时`seq`还是`101`)。当服务端收到报文后发现`ACK=1`并且`ack=301`，就知道客户端收到序列号为`300`的报文了，就这样客户端和服务端通过`TCP`建立了连接。

> 上面过程中，**第三次捂手是可以携带数据的，前两次握手不可以携带数据。**

#### 四次挥手

> 四次挥手的目的是关闭一个连接

当我们的应用程序不需要数据通信了，就会发起断开 `TCP` 连接。建立一个连接需要三次握手，而终止一个连接需要经过四次挥手。

假如客户端先发起关闭请求。

- 第一次挥手。客户端向服务端发送一个 FIN 报文，报文中会指定一个序号（假如`seq = u`)，这个时候客户端处于终止等待1 `FIN_WAIT_1` 状态，客户端会停止发送数据，主动关闭 TCP 连接，并等待服务端确认。

- 第二次挥手，服务端收到客户端的 FIN 报文后，就知道这是一个关闭请求。然后服务端向客户端返回一个确认报文，包含确认序号`ACK = 1`，`ack = seq + 1`,也就是`u+1`,并带上自己的序号`squ = v`,这时候服务端处于终止等待`CLOSE_WAIT` 状态，客户端进入`FIN_WAIT_2` 状态。TCP 处于半关闭状态，因为客户端不会发送数据了，不过服务器端有数据发送的话，客户端依然需要接收。

- 第三次挥手，如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。也就是服务端没有数据要向客户端发送了，服务端发出**连接释放报文段**包含（`FIN=1`，`ACK=1`，序号`seq=w`，确认号`ack=u+1`），服务端进入` LAST_ACK`（最后确认）状态，等待客户端的确认。

- 第四次挥手。客户端收到服务器的 `FIN` 包后，向服务端返回确认报文（`ACK=1，ack=w+1`），这个时候客户端就进入了 `TIME_WAIT` （时间等待）状态。注意此时 `TCP` 连接还没有释放，必须经过 `2*MSL` 后，才进入 `CLOSED` 状态。而服务器端收到客户端的确认包 `ACK` 后就进入了 `CLOSED` 状态，可以看出服务器端结束 `TCP` 连接的时间要比客户端早一些。

> 客户端：FIN_WAIT_1 --> FIN_WAIT_2 --> TIME_WAIT

> 服务端：LISTEN --> CLOSE_WAIT --> LAST_ACK --> CLOSED


#### Time_wait状态的链接过多会怎样

- 第一是内存资源占用，这个目前看来不是太严重，基本可以忽略。

- 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000 ，*也可以通过`net.ipv4.ip_local_port_range`指定*，如果 TIME_WAIT 状态过多，会导致无法创建新连接。

#### 如何优化 TIME_WAIT

- 一个暴力的方法是通过 `sysctl` 命令，将系统值调小。这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置，并且只打印出警告信息。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，**不推荐使用**。
- **调低 TCP_TIMEWAIT_LEN，重新编译系统**，这个方法是一个不错的方法，缺点是需要“一点”内核方面的知识，能够重新编译内核。我想这个不是大多数人能接受的方式。
- 设置`SO_LINGER`我们可以通过设置套接字选项，来设置调用 `close` 或者 `shutdown` 关闭连接时的行为。这个方法为跨越 TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。
- Linux 还提供了一种比较安全的方法，就是设置`net.ipv4.tcp_tw_reuse`选项,
从协议角度理解如果是安全可控的，可以复用处于 TIME_WAIT 的套接字为新的连接所用。

> sysctl 命令，调低 tcp_timewait_len 重新编译，SO_LINGER，net.ipv4.tcp_tw_reuse

**那么什么是协议角度理解的安全可控呢？主要有两点**：

1）只适用于连接发起方（C/S 模型中的客户端）；

2）对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。

使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，也就是`net.ipv4.tcp_timestamps=1`（默认即为 1）。



----

## 20210512

----

### 同步io和异步io

- 异步 IO

调用一个异步 IO 函数接收数据时，不管有没有数据，这个函数都会立即返回。我们在调用异步 IO 函数时要指定一个接受数据的缓冲区，还要指定一个回调函数，其他的事情操作系统去做了，程序可以自由地干其他事情。

- 同步 IO

调用一个同步 IO 函数接受数据时，在没有得到结果之前，这个调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。同步 IO 需要调用 2 个函数才能取到数据，它的优点就是得到了所谓的 IO 复用的能力。

### 优化数据库

高频访问：

* 分表分库：将数据库表进行水平拆分，减少表的长度
* 增加缓存： 在web和DB(数据库)之间加上一层缓存层
* 增加数据库的索引：在合适的字段加上索引，解决高频访问的问题

并发优化：

* 主从读写分离：只在主服务器上写，从服务器上读
* 负载均衡集群：通过集群或者分布式的方式解决并发压力

### B树和B+树的区别

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/Bptree.6qj0kx0hs900.png)

这都是由于B+树和B具有不同的存储结构所造成的区别，以一个m阶树为例。

1. **关键字的数量不同**；B+树中分支结点有m个关键字，它的孩子结点也有m个，其关键字只是起到了一个索引的作用，但是B树虽然也有m个子结点，但是其只拥有m-1个关键字。
2. **存储的位置不同**；B+树中的数据都存储在叶子结点上，也就是其所有叶子结点的数据组合起来就是完整的数据，但是B树的数据存储在每一个结点中，并不仅仅存储在叶子结点上。
3. `B+`树的所有叶节点之间有指针连接，所以可以进行范围查询，方便区间访问。
4. **查询不同**；B树在找到具体的数值以后，则结束，而`B+`树则需要通过索引找到叶子结点中的数据才结束，也就是说`B+`树的搜索过程中走了一条从根结点到叶子结点的路径。

B+树优点：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便查询，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来查找，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引，而B树则常用于文件索引。

### 长字符串找短字符串，可以使用hash吗

> 长字符串找短字符串 的方法

- 暴力破解

一种幼稚的做法是轮询第二个字符串里的每个字母，看它是否同在第一个字符串里。从算法上讲，这需要$O(n* m)$次操作，其中`n`是`string1`的长度，`m`是`string2`的长度。就拿上面的例子来说，最坏的情况下将会有$16*8 = 128$次操作。

- 排序后匹配

一个稍微好一点的方案是先对这两个字符串的字母进行排序，然后同时对两个字串依次轮询。两个字串的排序需要(常规情况)$O(m log m) + O(n log n)$次操作，之后的线性扫描需要$O(m+n)$次操作。同样拿上面的字串做例子，将会需要$164 + 83 = 88$加上对两个字串线性扫描的$16 + 8 = 24$的操作。(随着字串长度的增长，你会发现这个算法的效果会越来越好)

- hashtable匹配

最终，有一个最佳的算法，只需要$O(n+m)$次操作。方法就是，对第一个字串进行轮询，把其中的每个字母都放入一个`Hashtable`里(成本是$O(n)$或16次操作)。然后轮询第二个字串，在`Hashtable`里查询每个字母，看能否找到。如果找不到，说明没有匹配成功。这将消耗掉8次操作 —— 这样两项操作加起来一共只有24次。不错吧，比前面两种方案都要好。

### 各种排序的思路冒泡-快排-归并

* [常见排序算法](/寻offer总结/数据结构_场景应用/排序算法.md)

### TCP与UDP的区别

- 1.`TCP`面向连接，`UDP`无连接。
- 2.`TCP`面向字节流（文件传输），`UDP`是面向报文的，`UDP`没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（比如`IP`电话，实时视频会议等）。
- 3.`TCP`首部开销`20`字节，UDP的首部开销小，只有8个字节。
- 4.`TCP`的逻辑通信信道是全双工的可靠信道，提供可靠的服务。也就是说，通过`TCP`连接传送的数据，无差错，不丢失，不重复，且有序到达; `UDP`是不可靠信道，`UDP`只是尽最大努力交付，并不保证可靠交付。
- 5.每一条`TCP`连接只能是点到点的；`UDP`支持一对一，一对多，多对一和多对多的交互通信。
- 6.`TCP`对系统资源的要求高于`UDP`，所以速度也比`UDP`慢。
- 7.`TCP`数据包是没有边界的，会出现粘包的问题，`UDP`包是独立的，不会出现粘包问题。
- 所以在应用方面，如果强调数据的完整性和正确性用`TCP`，当要求性能和速度的时候，使用`UDP`更加合适。

#### TCP 包过大会怎样


如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解一块块的数据发送，而不是一次性发送所有数据。

- MTU：一个网络包的最大长度，以太网中一般为 1500 字节。
- MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/tcp分割数据.66xmbk7p3ig0.png)

数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。

再来看`UDP`数据报，由于`UDP`数据报不会自己进行分段，因此当长度超过了`MTU`时，会在网络层进行`IP`分片。同样，`ICMP`（在网络层中）同样会出现`IP`分片情况。  

**总结：`UDP`不会分段，就由`IP`来分。`TCP`会分段，当然就不用`IP`来分了！**

> PS: **内核缓冲区总是充满数据时会产生粘包问题**

-------

## 20200514

### MySQL存储引擎

存储引擎是`MYSQL`的核心技术，不同的存储引擎使用不同的存储机制、索引技巧、锁定水平并最终提供不同的功能和能力。常见的引擎分为三种：**InnoDB存储引擎（MYSQL默认的事务性引擎）、MyISAM存储引擎、Memory存储引擎**。

* InnoDB ： `InnoDB`是`mysql`的默认引擎，支持事务和外键，支持容灾恢复。适合更新频繁和多并发的表  行级锁

* MyISAM ： 插入和查询速度比较快，支持大文件，但是不支持事务，适合在`web`和数据仓库场景下使用  表级锁

* MEMORY ： `memory`将表中的数据保存在内存里，适合数据比较小而且频繁访问的场景

### 大小端怎么判断

计算机有两种存储数据的方式:**大端字节序** （big endian）和**小段字节序**（little endian）。

比如：数值0x2211使用两个字节储存：高位字节是0x22，低位字节是0x11

> - 大端字节序：高位字节在前面，低位字节在后面,这符合人类的读写数值方法
> - 小端字节序：地位字节在前面，高位字节在后面。

**为什么会有小端字节序？**

计算机都是从低位开始处理字节效率比较高，因为计算都是从低位开始的，因此计算机内部都是小端字节序。            
但是人类比较习惯大端字节序，所以除了计算机内部处理，其他场合一般都用大端字节序，比如网络参数，文件存储。

计算机在处理字节序的时候是按照顺序读取字节的，**如果是大端字节序，先读到的就是高位字节，后读到的就是低位字节。小端字节序正好相反。**

### `void*` 可以直接输出值吗

- `void *` 可以定义一个指针变量，但不说明它指向哪一种类型数据.

- `void *`可以强制转换成任何其他的类型

- 使用`void *`表示该函数指针可以不用指定为某种特定类型。例如，在套接字函数中，`send(void * pData, int nLength)`这意味着您可以通过多种方式调用它，`pData` 可以是字符串，甚至可以是一个对象。例如
  
  ```c
  char * data = "blah";
  send(data, strlen(data));
  POINT p;
  p.x = 1;
  p.y = 2;
  send(&p, sizeof(POINT));
  ```

- 指向`0`的地址,`(void *)0`，指向全是`0`的地址，相当于`NULL`。

- 可执行 赋值，取值操作，但**不能用于指定数据输出**，因为没有指定要输出的数据长度，如果可以输出，那么将会是一个无限长的输出。

### timewait状态多久，为什么要有

`TIME_WAIT`是指四次挥手中客户端接收了服务端的`FIN`报文并发送`ACK`报文给服务器后，仍然需要等待`2MSL`时间的过程。虽然按道理，四个报文都发送完毕，我们可以直接进入`CLOSED`状态了，但是我们必须假设网络是不可靠的，有可能最后一个`ACK`丢失。如果客户端发送的`ACK`发生丢失，服务器会再次发送`FIN`报文给客户端，所以`TIME_WAIT`状态就是用来重发可能丢失的`ACK`报文。

### B+树一个节点有多大？一千万条数据，B+树多高？

B+树一个节点的大小设为一页或页的倍数最为合适。因为如果一个节点的大小 `<` 1页，那么读取这个节点的时候其实读取的还是一页，这样就造成了资源的浪费。

在 MySQL 中 B+ 树的一个节点大小为“1页”，也就是`16k`。之所以设置为一页，是因为对于大部分业务，一页就足够了：

首先 InnoDB 的 B+ 树中，非叶子节点存的是`key` + 指针；叶子节点存的是数据行。

- 对于叶子节点，如果一行数据大小为`1k`，那么一页就能存`16`条数据；
- 对于非叶子节点，如果`key`使用的是`bigint`，也就是为`8`字节，指针在`mysql`中为`6`字节，一共是`14`字节，则`16k`能存放 $16 * 1024 / 14 = 1170$ 个索引指针。

于是可以算出，对于一颗高度为`2`的`B+`树，根节点存储索引指针节点，那么它有`1170`个叶子节点存储数据，每个叶子节点可以存储`16`条数据，一共 $1170 * 16 = 18720$ 条数据。

而对于高度为`3`的B+树，就可以存放 $1170 x 1170 x 16 = 21902400$ 条数据（两千多万条数据），也就是对于两千多万条的数据，我们只需要高度为`3`的`B+`树就可以完成，通过主键查询只需要`3`次`IO`操作就能查到对应数据。所以在 InnoDB 中`B+`树高度一般为`3`层时，就能满足千万级的数据存储，所以一个节点为`1`页，也就是`16k`是比较合理的。

### **海量数据问题**

#### 1亿数据数组找最大1万个


这道题的思路是，先拿 1w 个数建堆，然后依次添加剩余元素，如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆，这样，遍历完后，堆中的 所有节点的数 就是所需的最大的 1w 个。

**复杂度分析**

建堆时间复杂度是`O(m)`，堆调整的时间复杂度是`O(logm)`，最终时间复杂度等于，`1`次建堆时间`+n`次堆调整时间=`O(m+nlogm)=O(nlogm)`
这里的n为`10`亿，`m`为`1w`

**优化的方法**

可以把所有10亿个数据分组存放，比如分别放在`1000`个文件中。这样处理就可以分别在每个文件的`10^6`个数据中找出最大的`10000`个数，合并到一起在再找出最终的结果。


### 如何冲100亿 URL 中找出相同的 URL

> 问题：给定a、b两个文件，各存放50亿个url，每个url各占64B，内存限制是4GB，请找出a、b两个文件共同的url

由于每个`url`需要占`64B`，所以`50`亿个`url`占用空间大小为`50亿×64=5GB×64=320GB`,由于内存大小只有 4GB，因此不可能一次性把所有的url加载到内存中处理。

对于这种题目，一般采用**分治法**，即把一个文件中的`url`按照某一特征分成多个文件，使得每个文件的内容都小于`4GB`，这样就可以把这个文件一次性读入到内存中进行处理。

**解答**：

首先遍历文件 `a`，对遍历到的 `URL` 求 `hash(URL) % 1000`，根据计算结果把遍历到的 URL 存储到 `a0, a1, a2, ..., a999`，这样每个大小约为 `300MB`。使用同样的方法遍历文件 `b`，把文件 `b` 中的 `URL` 分别存储到文件 `b0, b1, b2, ..., b999` 中。

通过之前的划分，与`ai`中的`url`相同的`url`一定在`bi`中。由于`ai`与`bi`中所有的`url`的大小不会超过`4GB`，因此可以把它们同时读入内存中进行处理。

具体为：遍历文件`ai`，把遍历到的`url`存`入hash_set`中，接着遍历文件`bi`中的`url`，如果这个`url`在`hash_set`中存在，那么说明这个`url`是这两个文件共同的`url`，可以把这个`url`保存到另一个单独的文件中。当把文件`a0~a499`都遍历完成后，就找到了两个文件共同的`url`。

- 分而治之，进行哈希取余；
- 对每个子文件进行 HashSet 统计。

#### 100万url找到出现频率最高的100个

> 海量数据中找出出现次数最多的前10个URL（如何找出访问最多的IP，如何从大量数据中找出高频词）

> https://bbs.csdn.net/topics/391080906


关于海量数据问题：

[海量数据处理：如何从10亿个数中，找出最大的10000个数？（top K问题）](https://blog.csdn.net/sinat_42483341/article/details/108277388)

[面试必须掌握的十个海量数据问题及解决方案](https://blog.csdn.net/hitxueliang/article/details/52153476)

### STL中hashTable的实现

STL中的`hashtable`使用的是**开链法**解决`hash`冲突问题，`hashtable`表内的元素称为桶（`bucket`),而由桶所链接的元素称为节点（`node`), 如下图所示。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/哈希表01.2oeu7i4l7fo.png)

`HashTable` 中的 `bucket` 维护的 列表不是`list`，也不是 `slist`，而是自己定义的 `hashtable_node` 数据结构组成的`linked-list`,并使用`vector`存放桶元素。`hashtable`的迭代器只提供前进操作，不提供后退操作.

`hashTable` 中的 `bucket` 是由28个质数`[53, 97, 193,...,429496729]`实现的，在创建`hashtable`时，会根据存入的元素个数选择大于等于元素个数的质数作为`hashtable`的容量（也就是`vector`的长度），其中每个`bucket`所维护的`linked-list`长度也等于`hashtable`的容量。如果插入`hashtable`的元素个数超过了`bucket`的容量，就要进行重建`table`操作，也就是找出下一个质数，创建新的`buckets vector`，重新计算元素在新`hashtable`的位置。


> **哈希表的缺陷**：完全散列的散列表可保证在最坏O(1)时间内查找元素，前提条件是所有元素的取值集合是已知的，在此基础上来设计散列函数。

----------

## 20150516

### 五层协议，每层都有哪些协议

每一层的作用：

- 物理层：负责底层数据传输，就是为数据链路层提供二进制传输服务。如网线；网卡标准。 （比特`Bit`）

- 数据链路层：接收来自物理层的数据，并封装成帧，传送到网络层；如网卡`MAC`地址。（帧Frame），ARP，STP

- 网络层：定义`IP`编址，定义路由选择功能；如不同设备的数据转发。（包Packet），IP，ICMP

- 传输层：主要负责端到端之间传输数据；如 `TCP`、`UDP`。（段 Segments）

- 会话层：负责在网络中的两节点之间建立、维持和终止通信；如一个软件的数据分发给另一个软件。

- 表示层：数据格式标识，基本压缩加密功能。

- 应用层：各种应用软件，包括 `Web` 应用。HTTP，HTTPS，DNS，RTMP、FTP

### TCP怎么保证可靠传输的

- **确认和重传**：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。
- **数据校验**：`TCP`报文头有校验和，用于校验报文是否损坏。
- **数据合理分片和排序**：`tcp`会按最大传输单元(MTU)合理分片，接收方如果收到的数据不按顺序的时候，就会对它重新排序再交给应用层。
  - 而对于UDP：`IP`数据报如果大于1500字节，也就是大于`MTU`。这个时候就会对数据包进行分片，让每一片都少于`MTU`，由于`UDP`的特性，有些分片会被丢弃，所以导致最终无法重组数据包，导致丢弃整个`UDP`数据报。
- **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。
- **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

> 拥塞控制有四种算法，**慢启动、拥塞避免，快速重传和快速恢复**

### 说一下`TCP`怎么进行拥塞控制的？

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

`TCP` 主要通过四个算法来进行拥塞控制：**慢开始、拥塞避免、快速重传、快速恢复**。

- **慢启动**。慢启动算法的思路是当主机开始发送数据时，先以比较小的拥塞窗口进行发送，然后每次翻倍，也就是说，由小到大逐渐增加拥塞窗口的大小，而这个大小是指数增长的，即`1、2、4、8、16`
  
  * 为了防止拥塞窗口`cwnd`增长过大引起网络拥塞，还要另外设置一个慢启动阈值`ssthresh`状态变量，当拥塞窗口的大小超过慢启动阈值的时候（ `cwnd > ssthresh` 时），停止使用慢启动算法而改用拥塞避免算法。

- **拥塞避免**：设置慢启动阈值，一般开始都设为`65536`。拥塞避免是指当拥塞窗口大小达到这个阈值的时候，拥塞窗口的值不再指数上升，而是采用加法增加（也就是每经过一个往返时间`RTT`就把发送方的拥塞窗口大小`+1`），以此来避免拥塞。

- **快速重传**：当发送端连续收到三个重复的`ack`时，表示该数据段已经丢失，需要重发。这个时候慢启动阈值`ssth`变为原来一半，拥塞窗口`cwnd`变为`ssth+3`，然后使用`+1+1`的发（也就是每一轮`RTT`就+1）

- **快速恢复**。当超过设定的时间没有收到某个报文段的`ack`时，表示网络拥塞，慢启动阈值`ssth`变为原来一半，拥塞窗口`cwnd=1`，进入慢启动阶段。

### 静态多态和动态多态

- **静态多态**

静态多态：也称为编译期间的多态，编译器在编译期间完成的，编译器根据函数实参的类型(可能会进行隐式类型转换)，可推断出要调用那个函数，如果有对应的函数就调用该函数，否则出现编译错误。
静态多态有两种实现方式：

  1.函数重载：包括普通函数的重载和成员函数的重载

  2.函数模板的使用

- **动态多态**（动态绑定）

即运行时的多态，在程序执行期间(非编译期)判断所引用对象的实际类型，根据其实际类型调用相应的方法

**C++是依靠虚函数来实现动态多态的**

### C++虚函数相关，虚函数的实现原理

虚函数：在基类的函数前加上`virtual`关键字，在派生类中重写该函数，运行时将会根据对象的实际类型来调用相应的函数。如果对象类型是派生类，就调用派生类的函数；如果对象类型是基类，就调用基类的函数.

**`C++`的虚函数是实现多态的机制**。它是通过虚函数表和虚表指针实现的，虚表是一个指针数组，它存放着指向虚函数的指针，类的实例在调用虚函数时会在虚函数表中寻找函数地址进行调用，如果子类覆盖了父类的函数，则子类的虚函数表会指向子类实现的函数地址，否则指向父类的函数地址。一个类的所有实例都共享同一张虚函数表。

### 虚函数表是如何实现动态绑定的

>  虚函数的动态绑定是利用虚表和虚表指针类实现的

假如有一个类 B 继承另一个类 A ，如果基类 A 中有包含了虚函数，那么继承类 B 就可以调用基类 A 的虚函数，也就是说一个类继承了包含虚函数的基类，那么这个类就应有自己的虚表。

我们来看以下的代码。类 A 包含虚函数`vfunc1`，`vfunc2`，由于类 A 包含虚函数，故类 A 拥有一个虚表。

```cpp
class A {
public:
    virtual void vfunc1();
    virtual void vfunc2();
    void func1();
    void func2();
private:
    int m_data1, m_data2;
};
```

![虚函数表01](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/虚函数表01.png)

**虚表是一个指针数组，它存放着指向虚函数的指针**，普通函数也就非虚函数，它的调用不需要经过虚表，所以虚表中并没有存放指向非虚函数的指针。

为了指定对象的虚表，对象中包含一个指向虚表的指针，指向自己的虚表，为了让每个包含虚表的类的对象都用一个虚表指针，编译器在类中添加一个指针`*__vptr`，每个类创建的对象的时候这个指针默认指向类的虚表。

![虚函数表02](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/虚函数表02.png)

一个继承类的基类如果包含虚函数，那这个继承类也有拥有自己的虚表，故这个继承类的对象也包含一个虚表指针，用来指向它的虚表。

**那么C++ 是如何利用虚表和虚表指针来实现动态绑定的呢**？

```cpp
class A {
public:
    virtual void vfunc1();
    virtual void vfunc2();
    void func1();
    void func2();
private:
    int m_data1, m_data2;
};

class B : public A {
public:
    virtual void vfunc1();
    void func1();
private:
    int m_data3;
};

class C: public B {
public:
    virtual void vfunc2();
    void func2();
private:
    int m_data1, m_data4;
};
```

类 A 是基类，类 B 继承类 A，类 C 又继承类 B。类 A，类 B，类 C，其对象模型如下图所示。

![虚函数表03](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/虚函数表03.png)

由于这三个类都有虚函数，所以编译器为每个类都创建了一个虚表，即类 A 的虚表（`A vtbl`），类 B 的虚表（`B vtbl`），类 C 的虚表（`C vtbl`）。类 A，类 B，类 C 的对象都拥有一个虚表指针，`*__vptr`，用来指向自己所属类的虚表。

类 A 包括两个虚函数，故 `A vtbl` 包含两个指针，分别指向`A::vfunc1()`和`A::vfunc2()`。
类 B 继承于类 A，故类 B 可以调用类 A 的函数，但由于类 B 重写了`B::vfunc1()`函数，故 `B vtbl` 的两个指针分别指向`B::vfunc1()`和`A::vfunc2()`。
类 C 继承于类 B，故类 C 可以调用类 B 的函数，但由于类 C 重写了`C::vfunc2()`函数，故 `C vtbl` 的两个指针分别指向`B::vfunc1()`（指向继承的最近的一个类的函数）和`C::vfunc2()`。

综上所诉，对象的虚表指针用来指向自己所属类的虚表，虚表中的指针会指向它继承的最近的一个类的虚函数。

非虚函数的调用不用经过虚表，所以不需要虚表中的指针指向这些函数

### 多态时候基类的sizeof，子类的sizeof

根据虚函数的工作机制，通常编译器处理虚函数时会给对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针，因此类中添加虚函数后，sizeof(类名)应为该指针的大小。

> https://blog.csdn.net/weixin_42067304/article/details/108547910

### 为什么成员函数不占用类的空间

> https://blog.csdn.net/weixin_39888807/article/details/111103858

-------

## 好未来实习面试准备

### 对好未来产品的认识

学而思网校，学而思培优，挺好用的。我的堂弟堂妹都在用。

### 设计一个在线教育平台需要有哪些功能需求

- 学习功能，学生利用在线教育系统完成浏览课程信息，浏览实验信息，浏览课程内容，下载教学资源等功能。
- 交流功能，与现实中的教育一样，学生有可能会遇到各种自己无法解决的问题，就需要向别人求助，设计一个在线留言板就能够很好的解决这个问题，它能方便用户之间的交流，提高学习的效率-。
- 在线练习，学生熟悉课程内容之后，可以在系统上选择在线练习，这样学生可以通过练习使得自己得到提高，并且在完成试题后，可以随即查到所有试题的答案。
- 后台管理，在线学习平台的内容是不断更新的，这就需要教师适时的更新，这要求教师及时添加相关最新教学资源，同时及时反馈学生的问题，这样方便师生之间的交流。

### 非阻塞connect实现

在广域网中，`connect`函数可能需要比较长的时间返回（等待对端发送`ack`），所以我们通常需要非阻塞`connect`。

-  `fcntl` 函数可以将一个`socket` 句柄设置成非阻塞模式: 
-  采用信号处理函数设置阻塞超时控制。

- 第一步:创建`socket`,返回套接口描述符;
- 第二步:调用`fcntl`把套接口描述符设置成非阻塞;
- 第三步:调用`connect`开始建立连接;
- 第四步:判断连接是否成功建立;

A:如果`connect`返回0,表示连接不成功(服务器和客户端在同一台机器上时就有可能发生这种情况);

B:调用`select`来等待连接建立成功完成;

如果`select`返回`0`,则表示建立连接超时;我们返回超时错误给用户,同时关闭连接,以防止三路握手操作继续进行下去;

如果`select`返回大于0的值,则需要检查套接口描述符是否可读或可写;如果套接口描述符可读或可写,则我们可以通过调用`getsockopt`来得到套接口上待处理的错误(`SO_ERROR`),如果连接建立成功,这个错误值将是0,如果建立连接时遇到错误,则这个值是连接错误所对应的`errno`值(比如:`ECONNREFUSED`,`ETIMEDOUT`等).

> http://blog.chinaunix.net/uid-20205875-id-5761482.html

```c

bool nonblockingConnect(const char* ip, short port, int timeout = 3)
{
	int fd = socket(AF_INET, SOCK_STREAM, 0);
    if (fd == -1)
    {
        cout << "create socket failed" << endl;
        return false;
    }
 
    //设置非阻塞
	int flag = fcntl(fd, F_GETFL, 0);
	if (fcntl(fd, F_SETFL, flag | O_NONBLOCK) == -1)
	{
		cout << "fcntl failed" << endl;
		close(fd);
		return false;
	}
 
  //IPv4
	struct sockaddr_in srvAddr;
  //初始化
	memset(&srvAddr, 0, sizeof(struct sockaddr_in));
	srvAddr.sin_addr.s_addr = inet_addr(ip);
	srvAddr.sin_port = htons(port);
	srvAddr.sin_family = AF_INET;
 
    //为了处理EINTR,将connect放在循环内
    while (1)
    {
        int ret = connect(fd, (sockaddr*)&srvAddr, sizeof(struct sockaddr_in));
        if (ret == 0)
        {
            cout << "connect successfully" << endl;
            return true;
        }
        else if (ret == -1)
        {
            if (errno == EINTR)
            {
                cout << "signal interrupt" << endl;
                continue;
            }
            else if (errno != EINPROGRESS)
            {
                cout << "can not connect to server, errno: " << errno << endl;
                close(fd);
                return false;
            }
            else
            {
                break;
            }
        }
 
    }
 
	fd_set wfds;
    FD_ZERO(&wfds);
    FD_SET(fd, &wfds);
	timeval tv = { timeout, 0 };
 
	int ret = select(fd + 1, nullptr, &wfds, nullptr, &tv);
	if (ret <= 0)
	{
		cout << "can not connect to server" << endl;
		close(fd);
		return false;
	}
 
	if (FD_ISSET(fd, &wfds))
	{
		int error;
		socklen_t error_len = sizeof(int);
		ret = getsockopt(fd, SOL_SOCKET, SO_ERROR, &error, &error_len);
		if (ret == -1 || error != 0)
		{
			cout << "getsockopt connect failed, errno: " << errno << endl;
			return false;
		}
 
        /**
        * 在linux下，select返回fd可写，有两种情况：1.连接成功，2.发生错误
        * getsockopt返回error为0则排除错误情况，连接已建立
        */
        cout << "connect successfully" << endl;
 
        while (1)
        {
            int send_len = 0;
            const char buf[] = "hello\n";
 
            if ((send_len = send(fd, buf, sizeof(buf), 0)) == -1)
            {
                cout << "send failed";
                return false;
            }
            cout << "send len: " << send_len << endl;
            sleep(3);
        }
 
        return true;
    }
 
    cout << "can not connect to server, errno: " << errno << endl;
	close(fd);
	return false;
}
```

### 程序编译过程

> 执行 `gcc HelloWorld.c -o HelloWorld` 的过程

其实，GCC 只是完成编译工作的驱动程序，它会根据编译流程分别调用**预处理程序**、**编译程序**、**汇编程序**、**链接程序**来完成具体工作。

下图就是编译这段代码的过程：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/gcc编译过程.2h7in83bph60.jpg)

其实，我们也可以手动控制以上这个编译流程，从而留下中间文件方便研究：

- `gcc HelloWorld.c -E -o HelloWorld.i` **预处理**：加入头文件，替换宏。将源文件生成**预处理文件**。
- `gcc HelloWorld.i -s -c HelloWorld.s` **编译**：预处理文件生成**编译文件**。
- `gcc HelloWorld.s -c HelloWorld.o` **汇编**：将编译文件生成**汇编文件**。
- `gcc HelloWorld.o -o HelloWorld` **链接**：汇编文件生成**可执行文件**


### 静态库和动态库

#### 静态库
静态库可以认为是一些目标代码的集合, 是在**可执行程序运行前**就已经加入到执行代码中, 成为执行程序的一部分. 按照习惯, 一般以`.a`做为文件后缀名.

静态库的命名一般分为三个部分：
- 前缀：`lib`
- 库名称：自定义即可, 如`test`
- 后缀：`.a`

所以最终的静态库的名字应该为：`libtest.a`

#### 共享库/动态库

共享库在程序编译的时候是不会被连接到目标代码中, 而是**在程序运行时才被载入**。 不同的应用程序如果调用相同的库, 那么在内存里只需要有**一份该共享库**的拷贝, 规避了空间浪费问题。 动态库在程序运行时才被载入, 也解决了静态库对程序的更新、部署和发布会带来麻烦. 用户只需要更新动态库即可, 增量更新。为什么需要动态库, 其实也是静态库的特点导致。
按照习惯, 一般以”`.so`”做为文件后缀名. 共享库的命名一般分为三个部分：

- 前缀：`lib`
- 库名称：自己定义即可, 如`test`
- 后缀：`.so`

所以最终的静态库的名字应该为：`libtest.so`

### 写一个不能复制的类

老式写法：将构造函数和析构函数卸载`protected`中。然后将拷贝复制相关的实现设为私有

```cpp

class noncopyable
{
protected:
	noncopyable() {}
	~noncopyable() {}
private:
	noncopyable( const noncopyable& );
	noncopyable& operator=( const noncopyable& );
```

C++ 11 写法

```cpp
class noncopyable
{
protected:
  //constexp 编译期就可以算出来,限定在了编译期常量
	constexpr noncopyable() = default;
	~noncopyable() = default;
	noncopyable( const noncopyable& ) = delete;
	noncopyable& operator=( const noncopyable& ) = delete;
};
```

### 说一下`C++`里的智能指针

 `C++`里面的四个智能指针，`auto_ptr`，`unique_ptr`，`shared_ptr`，`weak_ptr`，其中后三个是c++11支持，并且第一个已经被`c++11`弃用。

 使用原因：智能指针的作用是管理一个指针，因为在程序设计中动态分配的堆内存没有正确释放或无法释放，导致资源浪费，程序运行速度变慢等问题。使用智能指针可以很大程度上的避免这个问题，因为智能指针是一个类，当超出了类的实例对象的作用域时，会自动调用对象的析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。

- `auto_ptr`：采用所有权模式。`p2`剥夺了`p1`的所有权，但是当程序运行时访问`p1`将会报错。所以`auto_ptr`的缺点是：存在潜在的内存崩溃问题。

- `unique_ptr`：实现独占式模式，保证同一时间内只有一个智能指针可以指向该对象。它对于避免资源泄露(例如“以`new`创建对象后因为发生异常而忘记调用`delete`”)特别有用，可以通过标准库的`move()`函数实现指针转移。

- `shared_ptr`：实现共享式拥有概念。多个智能指针可以指向相同对象，该对象和其相关资源会在“最后一个引用被销毁”时候释放。从名字`share`就可以看出了资源可以被多个指针共享，它使用**计数机制**来表明资源被几个指针共享。

- `weak_ptr`：是一种不控制对象生命周期的智能指针, `weak_ptr` 设计的目的是为配合 `shared_ptr` 而引入的一种智能指针来协助 `shared_ptr` 工作, 它只可以从一个 `shared_ptr` 或另一个 `weak_ptr` 对象构造, 它的构造和析构不会引起引用计数的增加或减少。

更详细的C++智能指针分析见《[C++智能指针](/C++随记/07C++智能指针)》

#### 智能指针出现循环引用怎么解决？

弱指针`weak_ptr`用于专门解决`shared_ptr`循环引用的问题，`weak_ptr`不会修改引用计数，也就是它存在与否并不影响对象的引用计数器。循环引用就是：两个对象互相使用一个`shared_ptr`成员变量指向对方。`weak_ptr`并不对对象的内存进行管理，在功能上类似于普通指针，然而一个比较大的区别是，`weak_ptr`**能检测到所管理的对象是否已经被释放，从而避免访问非法内存**。

### select和epoll的区别

[IO多路复用](/寻offer总结/linux编程/IO多路复用相关.md)

### https建立的过程

`https`包括**非对称加密**和**对称加密**两个阶段，在客户端与服务器建立连接的时候使用**非对称加密**，连接建立以后使用的是**对称加密**。

（1）客户端向服务器端发起`SSL`连接请求；<br>
（2） 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥<br>
（3）客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端<br>
（4）服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密，<br>
（5）进行数据传输，服务器和客户端用相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，也就是即使第三方获得数据包，也无法对其进行加密，解密和篡改。<br>

### DNS解析

#### `DNS`解析过程

如下图所示，详细阐述`DNS`解析流程。

- 客户机提出域名解析请求，并将该请求发送给本地的域名服务器。

- 当本地的域名服务器收到请求后，就先查询本地的缓存，如果有该记录项，则本地的域名服务器就直接把查询的结果返回。

- 如果没有，就到互联网中根服务器去查找，获取`.com`的顶级域名服务器

- 然后在`.com`的顶级域名服务器中进行查找，比如说获取`google.com`的授权域名服务器

- 在`google.com`的授权域名服务器中查找主机`www.google.com`的`IP`地址，最后将`IP`地址返回给计算机。

- 计算机获得`www.google.com`的`IP`地址后，用户就可以访问这个网站了。

### 什么时候用多进程，什么时候用多线程

https://blog.csdn.net/yu876876/article/details/82810178

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**
* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量`CPU`资源且切换频繁，所以多线程好一点
* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用**多进程**。因为线程之间的数据共享和同步比较简单。
* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

### 一个进程都分为那些内存空间

Linux进程可分为五部分：

代码区：存放可执行的指令操作，只能读不能写

全局区：存放未初始化的静态变量和全局变量

数据区：存放初始化的静态变量和全局变量

栈：存放临时变量，函数参数等

堆：存放`new/malloc`等动态申请的变量，用户必须手动进行`delete/free`操作

------

## 腾讯相关面经20210519

### C++内存分区

在操作系统中，不同应用程序之间的内存时相互独立的，一般不能互相进行访问。

一个引用程序的内存一般分成五个区：

- 栈区：栈区存储的是一些临时变量，包括局部变量，返回值，参数，返回地址等等。栈空间是有存储大小的，如果超过这个大小将会出现栈溢出。
- 堆区：堆区是一个比较大的内存空间，主要用来动态分配内存，这一部分通常由程序员进行分配和释放。如果在程序结束的时候还未释放，就会被操作系统回收。
- 全局区：存放未初始化的静态变量和全局变量
- 数据区：存放初始化的静态变量和全局变量
- 代码区：代码区存储的就是可执行的代码，这个区域的属性是只读的。

### `new/delete` 与 `malloc/free` 的异同

它们都用于动态申请内存和释放。

- `new/delete` 是`C++`的运算符,`malloc/free`是`C/C++`标准库函数，
- 在`C++`中分别使用`new` 和 `delete`来分配和释放内存。`new` 和 `delete`**是运算符，不是函数**。`new/delete`相对于`malloc/free`除了分配和释放内存之外还做了其他很多事情。
  - `new` 相对于 `malloc` 会额外的做一些初始化工作，
  - `delete` 相对于 `free` 多做一些清理工作。
  - 比如说使用`new`生成一个对象时，系统会调用这个类的构造函数，使用`delete`删除一个对象时，系统会调用这个类的析构函数。


```cpp
class A
{
 public:
     A()
     {
        cont<<"A()构造函数被调用"<<endl;
     }
     ~A()
     {
        cont<<"~A()构造函数被调用"<<endl;
     }
}

//在 main 主函数中，加入如下代码

A* pa = new A();  //类 A 的构造函数被调用
delete pa;        //类 A 的析构函数被调用
```

- `new`是封装了`malloc`，直接`free`不会报错，但是这只是释放内存，而不会析构对象。

### C++如何检测内存泄露

1）使用一些工具

比如，VC自带的 CRT 调试器和 CRT 调试堆函数

当程序退出时`CRT`会在`main()`函数返回之后做一些清理工作，这个时候来检查调试堆内存，如果仍然有内存没有被释放，则一定是存在内存泄漏。从这些没有被释放的内存块的头中，就可以获得文件名及行号。

缺点：只能检测出内存泄漏及其泄漏点的文件名和行号，但是并不知道泄漏究竟是如何发生的，并不知道该内存分配语句是如何被执行到的。

2）不适用工具

在申请内存时记录下该内存的地址和在代码中申请内存的位置，在内存销毁时删除该地址对应的记录，程序最后统计下还有哪条记录没有被删除，如果还有没被删除的记录就代表有内存泄漏。

我们都知道`new`关键字更底层是通过`operator new`来申请内存的

```cpp
void* operator new(std::size_t sz)
```

也就是正常情况下C++都是通过`operator new(std::size_t sz)`来申请内存，而这个操作符我们可以重载：

```cpp
void* operator new(std::size_t size, const char* file, int line);
void* operator new[](std::size_t size, const char* file, int line);
```

> `new`只会调用一次构造函数，而`new[]`会调用每个成员的构造函数。

如果能让程序申请内存时调用重载的这个函数，就可以记录下内存申请的具体位置啦。

我们可以对`new`使用宏定义让底层程序申请内存时调用重载的这个函数
``` pp
#define new new (__FILE__, __LINE__)
```

有了这个宏定义后，在`new A`的时候底层就会自动调用`operator new(std::size_t size, const char* file, int line)`函数，至此达到了我们记录内存申请位置的目的。

**哪里存储具体信息**？

我们肯定不能让它递归调用啊，那这些信息存储在哪里呢？这里可以在每次申请内存时，一次性申请一块稍微大点的内存，具体信息存储在**多余的那块内存里**，

> https://www.zhihu.com/question/29859828

### STL几大部件

- 容器：容纳一组元素的对象。

- 迭代器：提供一种访问容器中每个元素的方法。

- 函数对象：一个行为类似函数的对象，调用它就像调用函数一样。

- 算法：包括查找算法、排序算法等等。

- 适配器：用来修饰容器等，比如`queue`和`stack`，底层借助了`deque`。

- 空间配置器：负责空间配置和管理。

### map、set是怎么实现的,为什么

1)  他们的底层都是以**红黑树**的结构实现，因此插入删除等操作都在`O(logn）`时间内完成，因此可以完成高效的插入删除；

2)  实现`map`的红黑树的节点数据类型是`key+value`，而实现`set`的节点数据类型是`value`

3)  **因为`map`和`set`要求是自动排序的，红黑树能够实现这一功能，而且时间复杂度比较低**。

### 发送缓冲区

当 TCP 三次握手成功，TCP 连接成功建立后，操作系统内核会为每一个连接创建配套的基础设施，比如**发送缓冲区**。

发送缓冲区的大小可以通过套接字选项来改变，当我们的应用程序调用 `write ` 函数时，实际所做的事情是**把数据从应用程序中拷贝到操作系统内核的发送缓冲区中**，并不一定是把数据通过套接字写出去。

- 如果内核的发送缓冲区足够大，那么我们的程序从`write()`调用结束退出后，返回的字节数就是应用程序的数据大小。

- 发送缓冲区不足以容纳所有的应用程序数据，这时候应用程序被阻塞，也就是应用程序在`write()`函数调用处停留，不直接返回。

### 树的遍历和应用场景

- 前序遍历
  - 第一次访问就输出数据
  - 适合静态访问

- 中序遍历
  - 对于二分搜索树，输出结果是有序的
  - 适合顺序输出结果

- 后序遍历
  - 对节点操作时必访问过其子节点
  - 适合进行破坏性操作（删除节点）

### 函数栈的大小查看，怎么更改大小

- CentOS系统下可以使用`ulimit -s` 查看当前函数栈大小：

- 使用`ulimit -s sum` 可以将函数栈大小设置为 `sum KB` 大小：

### UDP怎么实现可靠传输

 传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照`tcp`可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。

**确认机制**

`UDP`要想可靠，就要接收方收到`UDP`之后回复个确认包，

**超时重传**

发送方有个机制，收不到确认包就要重新发送，每个包有递增的序号，接收方发现中间丢了包就要发重传请求，。

**滑动窗口**

当网络太差时候频繁丢包，防止越丢包越重传的恶性循环，要有个发送窗口的限制，发送窗口的大小根据网络传输情况调整，调整算法要有一定自适应性。

> 可参考：https://blog.csdn.net/u013474436/article/details/105583260

------

## 20210520

> 情人节快乐

### http和https的区别

- `http` 是超文本传输协议，信息是明文传输的， `https` 则是具有安全性的 `ssl` 加密传输协议
- `http` 和 `https` 使用的是完全不同的连接方式，用的端口也不一样，`http`是 `80` ，`https`是 `443`
- `http` 的连接很简单，是无状态的； `HTTPS` 协议比 `http` 协议更加安全。

- `HTTPS`协议[**使用混合加密和摘要算法**]解决了`HTTP`协议的一些不足，因为 `HTTP`：
  - 1.通信使用明文（不加密），内容可能会被盗取
  - 2.不验证通信方身份，因此可能遭遇伪装
  - 3.无法证明报文的完整性（即准确性），所以可能已遭篡改      

> HTTP+加密+认证+完整性保护=HTTPS

由`HTTP`升级为`HTTPS`需要到 `CA` 申请证书，一般免费证书较少，因此需要一定费用

### 拥塞控制和流量控制的区别

拥塞控制是防止过多的数据注入到网络中，导致网络发生拥塞；

而流量控制是防止发送方一下子发送过多的数据到接收方，导致接收方缓存放不下。

两种算法都是对发送方的行为进行控制的。

具体地说：

- 流量控制属于通信双方协商；拥塞控制涉及通信链路全局。

- 流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的`TCP`报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。

- `实际最终发送窗口 = min{流控发送窗口，拥塞窗口}`。

### 流量控制的介绍，采用滑动窗口会有什么问题

所谓流量控制就是让发送方发送速率不要过快，让接收方来得及接收。利用`TCP`报文段中的窗口大小字段来控制发送方的发送窗口不大于接收方接收的窗口大小就可以实施流量控制。

考虑一种特殊的情况，就是接收方若没有缓存足够使用，就会发送零窗口大小的报文，此时将发送方将的发送窗口设置为`0`，停止发送数据。之后接收方有足够的缓存，发送了非零窗口大小的报文，但是这个报文在中途丢失的，那么发送方的发送窗口就一直为零**导致死锁**。

解决这个问题，`TCP`为每一个连接设置一个持续计时器（`persistence timer`）。只要`TCP`的一方收到对方的零窗口通知，就启动这个计时器，周期性的发送一个零窗口探测报文段。对方就在确认这个报文的时候给出现在的窗口大小（注意：`TCP`规定，即使设置为零窗口，也必须接收以下几种报文段：零窗口探测报文段、确认报文段和携带紧急数据的报文段）。

### TCP 滑动窗口协议

`TCP`的滑动窗口用来控制接收方和发送方的发送速率，避免拥塞的发生。滑动窗口其实就是**接收端的缓冲区大小**，用来告诉发送方对它发送的数据有多大的缓冲空间。在接收方的滑动窗口已知的情况下，当接收方确认了一个连续的数据序列之后，发送方的滑动窗口向后滑动，发送下一个数据序列。

接收方会在每个`ACK`数据包中附带自己当前的接受窗口（滑动窗口）的大小，方便发送方进行控制。

### 线程安全问题

#### 为什么会有线程安全问题

当多个线程同时共享同同一个全局变量或静态变量，做写的操作时，可能会发生数据冲突问题，也就是线程安全问题。但是做读的操作不会发生线程安全问题。

#### 如何解决多线程之间线程安全问题

使用多线程之间同步synchronized或使用锁（lock），将可能会发生数据冲突问题（线程不安全问题），只能让当前一个线程进行执行。代码执行完成后释放锁，然后才能让其他线程进行执行。这样的话，就可以解决线程不安全问题。

### 进程_线程的互斥与同步的实现和使用

在进程/线程并发执行的过程中，进程/线程之间存在协作的关系，例如有互斥、同步的关系。

为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：

- 锁：加锁、解锁操作；
- 信号量：P、V 操作；

这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步。

#### 进程同步方式

信号量和管程机制

* **信号量**：信号量可以说是类似一个计数器，它控制的是多个进程对一个共享资源的访问，就是说这个资源最多能被多少个进程进行访问。[见上面进程间通信的信号量的PV操作初始化为0的时候就实现了进程间同步](#信号量的两种原子操作)

* **管程**: 信号量机制功能强大，但使用时对信号量的操作分散，而且难以控制，读写和维护都很困难。因此后来又提出了一种集中式同步进程——管程。其基本思想是**将共享变量和对它们的操作集中在一个模块中**，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，可以保证正确性。 

* **优缺点**： 

  * 1）信号量（Semaphore）及PV操作
  
   优：PV操作能够实现对临界区的管理要求；实现简单；允许使用它的代码休眠，持有锁的时间可相对较长。 

   缺：信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点。信号量机制功能强大，但使用时对信号量的操作分散，而且难以控制，读写和维护都很困难。加重了程序员的编码负担；核心操作P-V分散在各用户程序的代码中，不易控制和管理；一旦错误，后果严重，且不易发现和纠正。 

  * 管程
  
   优： 集中式同步进程——管程。其基本思想是将共享变量和对它们的操作集中在一个模块中，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，易于保证正确性。 

   缺：如果一个分布式系统具有多个CPU，并且每个CPU拥有自己的私有内存，它们通过一个局域网相连，那么这些原语将失效。而管程在少数几种编程语言之外又无法使用，并且，这些原语均未提供机器间的信息交换方法。 

#### 线程同步的方式

实现线程间同步的方法：

**互斥量，自旋锁，读写锁，条件变量**

- **互斥量**：比如说有两个线程，线程1和线程2，分别充当生产者与消费者的角色，那么这两个线程就很有可能同时去操作临界资源，如果同时去操作临界资源的话就会引起线程同步问题，互斥量的话就是来解决这个问题，当一个线程，比如说线程1在操作临界资源的时候，它就会阻止另外的线程去访问这个临界资源。其实引发线程同步问题的最根本原因是**这两个线程的指令是交叉执行的**，互斥量能够保证指令执行的原子性，也就是说先执行完线程1的指令再执行线程2的指令，或者先执行完线程2的指令再执行线程1的指令。保证他们之间不会出现交叉执行的情况。互斥量也称为互斥锁，它要么处于加锁状态要么处于解锁状态。保证资源访问的串行。操作系统提供的API是`pthread_mutex_t`。

- **自旋锁**：其实自旋锁和互斥锁的原理是一样的，都是在使用临界资源之前加一个锁，阻止其他线程对它进行访问，完成之后再把锁给释放掉，保证临界资源的串行访问。但是它和互斥锁还是存在差别的，使用自旋锁的线程会一直循环反复检查锁的变量是否可用，因此**它不会让出CPU**，会处于忙等待的状态。其实自旋锁还是有很多好处的，它避免了进程或者线程上下文切换的开销，如果锁使用的时间不是很长的话，使用自旋锁的代价也是很小的，同时在操作系统内部很多地方使用的是自旋锁而不是互斥量的。这里还要提一点就是**自旋锁不适合在单核`CPU`中使用**。因为自旋锁在等待的时候并不会释放`CPU`，而是死循环地去等待。会引起其他的进程或者线程无法去执行。操作系统提供的API是`pthread_spinock_t`。

- **读写锁**: 读写锁和互斥锁还有自旋锁是类似的，但是做了一些改进，基于临界资源的考量，因为在开发环境中，临界资源很可能会出现多读少写的特性，就比如有一个数据库存储的是历史订单信息，而这些订单我们一般只是去查询很少去改变它，这个存储历史订单的数据库就属于多读少写的临界资源，如果在读写的时候也给它加锁，这样的话效率会很低的。读写锁的话是一种特殊的自旋锁，**它允许多个读者同时读取临界资源，但是不允许多个写操作同时访问这个资源**。在操作系统中提供的API是`thread_rwlock_t`，读锁是通过`thread_rwlock_rdlock`来加的，写锁是通过`thread_rwlock_wdlock`来加的.


- **条件变量**：条件变量是一种先对复杂的线程同步方法，它允许线程睡眠，在满足一定条件的时候再唤醒线程，就是当满足条件时，可以向这个线程发送信号，唤醒这个线程。因为在生产者和消费者模型中是存在问题的，举个例子，比如当缓冲区小于或者等于0时，这时候应该不允许消费者继续消费，消费者必须等待，当缓冲区满的时候，这个时候应该不允许生产者往里面生成数据了，生产者必须处于等待状态。条件变量呢就是对这个问题进行了约束，当缓冲区为0的时候，如果有生产者生产一个产品，那么就要唤醒可能等待的消费者；当缓冲区满的时候，如果有消费者消费了产品，就需要唤醒其他可能在等待的生产者。操作系统提供的`API`是`pthread_cont_t`来定义的,等待是通过`pthread_cont_wait`定义的，,唤醒是通过`pthread_cont_notify`定义的。

### 二叉搜索树找第k个数

对二叉搜索树进行中序遍历，将遍历后的结果存到数组中，数组中的第`k`个元素就是二叉搜索树的第`k`小元素，因为二叉搜索树中序遍历后得到的结果就是得到的

**优化：遍历到第K大则停止遍历**

[见：二叉搜索树的第k大节点算法](/算法/NK-研发最爱考?id=剑指-offer-54二叉搜索树的第k大节点)


-------
## 20210521

### Linux常用命令，怎么查看内存和端口

- 使用`ifconfig` 查看自己的`IP`地址

- `find`和`grep`命令查找文件或者文件内容

```bash
# 按照文件名查找文件
find ./ -name "*.cpp" | grep "mian"

# xargs 查看文件里面的内容
find ./ -name "*llo" | xargs  grep -n -i "World"    # 加 -n 是显示行 加-i是不区分大小写
```

- `top`命令用于实时显示 进程或者系统 的动态，查看内存占用情况。

- 使用管道			

比如`ps -ef | grep bash`这里的`|`就是匿名管道，可以使用`mkfifo myPipe`创建有名管道

- `kill -l` 命令查看信号，或者使用`kill -9 进程号`杀死一个进程


- 通过`ps aux`查看进程的状态

当时在实习的时候，用的比较多网络相关的命令吧。比如：

- 查看主机名字
  - `hostname`
    - hostname –d 显示机器所属域名
    - hostname –f 显示完整的主机名和域名
    - hostname –i 显示当前机器的 ip 地址
- `ping`命令确认网络是否通畅
- `telnet`命令，通过 `telnet` 协议连接目标主机，如果 `telnet` 连接可以在任一端口上完成就代表着两台主机间的连接良好。
  - `telnet hostname port` –-> 使用指定的端口 `telnet` 主机名。这通常用来测试主机是否在线或者网络是否正常。
- `netstat`: 查看网络连接情况，查看端口是否被监听，
  - `netstat –tcp or netstat –t` 将会显示 `TCP` 连接
  - `netstat –udp or netstat –u` 将会显示 `UDP` 连接
  - `netstat -g` 将会显示该主机订阅的所有多播网络。

- 还有的话可以借助一些命令排插·，比如说，`pstack`,用来跟踪进程栈，我们发现一个服务一直处于`work`状态（如假死状态，好似死循环），使用这个命令就能轻松定位问题所在；可以在一段时间内，多执行几次`pstack`，若发现代码栈总是停在同一个位置，那个位置就需要重点关注，很可能就是出问题的地方；

### 数组和链表的内存存储和插入

- 数组的内存空间时连续的；链表是不连续的。
- 数组插入需要移位，空间不够需要扩容；链表直接插入即可。

### unordered_map 和 map 的底层实现，以及使用场景如何选择

> STL中unordered_map和map的区别

* `unordered_map`是C++ 11新添加的容器,底层使用哈希表实现的，占用内存比较多，查询速度比较快，其查询时间复杂度为`O(1)`。它内部是**无序**的，需要实现`==`操作符。
* `map`底层是采用红黑树实现的，插入删除查询时间复杂度都是`O(log(n))`，它的内部是**有序**的，因此需要实现比较操作符(`<`)。

如果你考虑效率，特别是在元素达到一定数量级时，可以考虑使用`unordered_map` 。但若你对内存使用特别严格，希望程序尽可能少消耗内存，那么就要谨慎使用`unordered_map`，因为它占用内存比较大，而且`unordered_map` 的构造速度较慢。

`map`适用于有序数据的应用场景，`unordered_map`适用于高效查询的应用场景


### `#include`时`“”`和`<>`的区别

`#include<>`：编译器直接从系统类库目录里查找头文件：

`#include""`：默认从项目当前目录查找头文件，所谓项目当前目录，就是项目工程文件（`.vcxproj`）所在的目录。如果在项目当前目录下查找失败，再从项目配置的头文件引用目录查找头文件，所谓项目配置的引用目录，就是我们在项目工程中设置的头文件引用目录。如果项目配置的头文件引用目录中仍然查找失败，再从系统类库目录里查找头文件
> 项目当前目录 --> 配置的引用目录 --> 系统类库目录


### 构造函数和析构函数可以调用虚函数吗，为什么

#### 构造函数为什么一般不定义为虚函数

1）因为创建一个对象时需要确定对象的类型，而虚函数是在运行时确定其类型的。而在构造一个对象时，**由于对象还未创建成功，编译器无法知道对象的实际类型**，是类本身还是类的派生类等等

2）虚函数的调用需要虚函数表指针，而该指针存放在对象的内存空间中；若构造函数声明为虚函数，那么由于对象还未创建，还没有内存空间，更没有虚函数表地址用来调用虚函数，所以构造函数不能定义为虚函数。

 3） 从使用角度，虚函数主要用于在信息不全的情况下，能使重载的函数得到相应的调用。

#### 基类的析构函数为什么一般写成虚函数

首先析构函数可以为虚函数，当析构一个指向子类的父类指针时，编译器可以根据虚函数表寻找到子类的析构函数进行调用，从而正确释放子类对象的资源。

如果析构函数不被声明成虚函数，则编译器实施静态绑定，在删除指向子类的父类指针时，只会调用父类的析构函数而不调用子类析构函数，这样就会造成子类对象析构不完全造成内存泄漏。

> 直接的讲，C++中基类采用`virtual`虚析构函数是为了防止内存泄漏。


#### 构造函数或者析构函数中调用虚函数会怎样

在构造函数中调用虚函数，由于当前对象还没有构造完成，此时调用的虚函数指向的是基类的函数实现方式。

在析构函数中调用虚函数，此时调用的是子类的函数实现方式。


### 介绍一下HTTP/1 HTTP/2 HTTP/3的发展

- 技术的发展都是为了解决某些问题
- `HTTP/1`的问题是短链接每次都需要`TCP`的三次握手四次挥手、不安全（后面有了`HTTPS`解决安全问题）、无状态（可以使用 Cookie 用户信息）、服务端不能主动发送。

- `HTTP/2`默认了长连接（Conection: Keep-Alive）、引入`TLS/SSL`、`Cookie`、服务端主动发送、头部压缩、多路复用。但是还有队头阻塞的问题（因为虽然进行了长连接，但是还有一种情况会出现队头阻塞，那就是 丢失重传）。

- `HTTP/3`使用`UDP`解决了丢失重传导致的队头阻塞，并且使用了`TLS/SSL1.3`减少了建立`HTTPs`连接的时间到`1.5-2`个RTT（往返时间），还引入了二进制编码，其他细节忘记了。

### 纯虚函数

纯虚函数是只有声明没有实现的虚函数，是对子类的约束，是接口继承

包含纯虚函数的类是抽象类，它不能被实例化，只有实现了这个纯虚函数的子类才能生成对象

使用场景：当这个类本身产生一个实例没有意义的情况下，把这个类的函数实现为纯虚函数，比如动物可以派生出老虎兔子，但是实例化一个动物对象就没有意义。并且可以规定派生的子类必须重写某些函数的情况下可以写成纯虚函数。

#### 虚函数和纯虚函数区别

- 虚函数是为了实现动态绑定产生的，目的是通过基类类型的指针指向不同对象时，自动调用相应的、和基类同名的函数（使用同一种调用形式，既能调用派生类又能调用基类的同名函数）。虚函数需要在基类中加上`virtual`修饰符修饰，因为`virtual`会被隐式继承，所以子类中相同函数都是虚函数。当一个成员函数被声明为虚函数之后，其派生类中同名函数自动成为虚函数，在派生类中重新定义此函数时要求函数名、返回值类型、参数个数和类型全部与基类函数相同。

- 纯虚函数只是相当于一个接口名，所以含有纯虚函数的类不能够实例化。


纯虚函数首先是虚函数，其次它没有函数体，取而代之的是用“`=0`”。

既然是虚函数，它的函数指针会被存在虚函数表中，由于纯虚函数并没有具体的函数体，因此它在虚函数表中的值就为`0`，而具有函数体的虚函数则是函数的具体地址。

一个类中如果有纯虚函数的话，称其为抽象类。抽象类不能用于实例化对象，否则会报错。抽象类一般用于定义一些公有的方法。子类继承抽象类也必须实现其中的纯虚函数才能实例化对象。

举个例子：

```C++
#include <iostream>
using namespace std;

class Base
{
public:
	virtual void fun1()
	{
		cout << "普通虚函数" << endl;
	}
	virtual void fun2() = 0;
	virtual ~Base() {}
};

class Son : public Base
{
public:
	virtual void fun2() 
	{
		cout << "子类实现的纯虚函数" << endl;
	}
};

int main()
{
	Base* b = new Son;
	b->fun1(); //普通虚函数
	b->fun2(); //子类实现的纯虚函数
	return 0;
}
```

 ### STL中vector的实现

 #### vector扩容

STL中的`vector`是封装了动态数组的顺序容器。不过与动态数组不同的是，`vector`可以根据需要自动扩大容器的大小。具体策略是每次容量不够用时重新申请一块大小为原来容量两倍的内存，将原容器的元素拷贝至新容器，并释放原空间，返回新空间的指针。

在原来空间不够存储新值时，每次调用`push_back`方法都会重新分配新的空间以满足新数据的添加操作。如果在程序中频繁进行这种操作，还是比较消耗性能的。

#### vector频繁对vector调用push_back对性能的影响和原因


如果需要频繁插入，最好先指定`vector`的大小，因为`vector`在容器大小不够用的时候会重新申请一块大小为原容器两倍的空间，并将原容器的元素拷贝到新容器中，并释放原空间，这个过程是十分耗时和耗内存的。频繁调用`push_back()`会使得程序花费很多时间在`vector`扩容上，会变得很慢。这种情况可以考虑使用`list`。

#### C++中vector和list的区别

`vector`和数组类似，拥有一段连续的内存空间。`vector`申请的是一段连续的内存，当插入新的元素内存不够时，通常以2倍重新申请更大的一块内存，将原来的元素拷贝过去，释放旧空间。因为内存空间是连续的，所以在进行插入和删除操作时，会造成内存块的拷贝，时间复杂度为`o(n)`。

`list`是由双向链表实现的，因此内存空间是不连续的。只能通过指针访问数据，所以`list`的随机存取非常没有效率，时间复杂度为`o(n)`; 但由于链表的特点，能高效地进行插入和删除。

`vector`拥有一段连续的内存空间，能很好的支持随机存取，因此`vector::iterator`支持“+”，“+=”，“<”等操作符。

list的内存空间可以是不连续，它不支持随机访问，因此`list::iterator`则不支持“+”、“+=”、“<”等

`vector::iterator`和`list::iterator`都重载了“`++`”运算符。

总之，如果需要高效的随机存取，而不在乎插入和删除的效率，使用`vector`;

如果需要大量的插入和删除，而不关心随机存取，则应使用`list`。

### 内存页面置换算法

#### 什么是缺页异常,缺页中断

当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：

- 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
- 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。

缺页中断的处理流程:

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/缺页字段01.3cmrr0n9o280.png)

- 1.在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。
- 2.如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
- 3.操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。
- 4.找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。
- 5.页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
- 6.最后，CPU 重新执行导致缺页异常的指令。

上面所说的过程，第 4 步是能在**物理内存找到空闲页的情况，那如果找不到呢**？

#### 常见的页面置换算法

找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。

- **最佳页面置换算法**

最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。

所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。

我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/页面置换算法01.2wgngjl2xbs0.png)

在这个请求的页面序列中，缺页共发生了 7 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 4 次。

这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。

所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

- **先进先出置换算法**

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以选择在内存驻留时间很长的页面进行中置换，这个就是「先进先出置换」算法的思想。

还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/页面置换算法02.7afmxqmvhlk0.png)

在这个请求的页面序列中，缺页共发生了 10 次，页面置换共发生了 7 次，跟最佳页面置换算法比较起来，性能明显差了很多

- **最近最久未使用的置换算法**

最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/页面置换算法03.3g5e8n36ic80.png)

在这个请求的页面序列中，缺页共发生了 9 次，页面置换共发生了 6 次，跟先进先出置换算法比较起来，性能提高了一些。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

- **时钟页面置换算法**

那有没有一种即能优化置换的次数，也能方便实现的算法呢？

时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。

该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

当发生缺页中断时，算法首先检查表针指向的页面：

如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；
我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/页面置换算法04.1f0v12op771c.png)

- **最不常用算法**

最不常用（LFU）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是<u>当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。</u>

<u>它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。</u>

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

<u>要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。</u>

<u>但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。</u>

那这个问题的解决的办法还是有的，<u>可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。</u>

------

## 好未来实习一面

> 以下回答全部是基于MySQL的InnoDB引擎,参考[这里](https://mp.weixin.qq.com/s/RemJcqPIvLArmfWIhoaZ1g)

### 什么是最左前缀原则

例如对于下面这一张表

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/左前缀01.5x44tzpjya40.webp)

如果我们按照 name 字段来建立索引的话，采用B+树的结构，大概的索引结构如下

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/左前缀02.1fyfrwjljwtc.png)

如果我们要进行模糊查找，查找name 以“张"开头的所有人的ID，即 sql 语句为

```sql
select ID from table where name like '张%'
```

由于在 B+ 树结构的索引中，索引项是按照索引定义里面出现的字段顺序排序的，索引在查找的时候，可以快速定位到 ID 为 100 的张一，然后直接向右遍历所有张开头的人，直到条件不满足为止。

也就是说，我们找到第一个满足条件的人之后，直接向右遍历就可以了，由于索引是有序的，所有满足条件的人都会聚集在一起。

而这种定位到最左边，然后向右遍历寻找，就是我们所说的**最左前缀原则**。

### 为什么用 B+ 树做索引而不用哈希表做索引

1、哈希表是把索引字段映射成对应的哈希码然后再存放在对应的位置，这样的话，如果我们要进行模糊查找的话，显然哈希表这种结构是不支持的，只能遍历这个表。而B+树则可以通过最左前缀原则快速找到对应的数据。

2、如果我们要进行范围查找，例如查找ID为`100 ~ 400`的人，哈希表同样不支持，只能遍历全表。

3、索引字段通过哈希映射成哈希码，如果很多字段都刚好映射到相同值的哈希码的话，那么形成的索引结构将会是一条很长的链表，这样的话，查找的时间就会大大增加。


### 主键索引和非主键索引有什么区别
### 主键索引与普通索引哪个快

例如对于下面这个表(其实就是上面的表中增加了一个k字段),且ID是主键

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/主键与非主键01.4fyl1w7q6k60.webp)

主键索引和非主键索引的示意图如下：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/主键与非主键02.258qkc85epkw.webp)

其中R代表一整行的值。

从图中不难看出，**主键索引和非主键索引的区别是**：

- 主键索引的叶子节点存的是**整行数据**。在 InnoDB 里，主键索引也被称为聚簇索引
- 非主键索引的叶子节点内容是**主键的值**。在 InnoDB 里，非主键索引也被称为二级索引

再看看他们在查询上有什么区别：

1、如果查询语句是 `select * from table where ID = 100`,即主键查询的方式，则只需要搜索 ID 这棵 B+树。

2、如果查询语句是 `select * from table where k = 1`，即非主键的查询方式，则先搜索k索引树，得到 ID=100,再到ID索引树搜索一次，这个过程也被称为回表。

> 所以主键索引查询更快


### 为什么建议使用主键自增的索引

对于这颗主键索引的树

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引01.25xndi6itrog.png)

如果我们插入 `ID = 650` 的一行数据，那么直接在最右边插入就可以了

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/自增索引02.571rsw3p9so0.webp)


但是如果插入的是 `ID = 350` 的一行数据，由于 B+ 树是有序的，那么需要将下面的叶子节点进行移动，腾出位置来插入 `ID = 350` 的数据，这样就会比较消耗时间，如果刚好 R4 所在的数据页已经满了，需要进行页分裂操作，这样会更加糟糕。

但是，如果我们的主键是自增的，每次插入的 ID 都会比前面的大，那么我们每次只需要在后面插入就行， 不需要移动位置、分裂等操作，这样可以提高性能。也就是为什么建议使用主键自增的索引。

------

## 好未来实习二面

### `unordered_map`和`map`的区别

* `unordered_map`是C++ 11新添加的容器,底层使用**哈希表**实现的，占用内存比较多，查询速度比较快，其查询时间复杂度为`O(1)`。它内部是**无序**的，需要实现`==`操作符。
* `map`底层是采用**红黑树**实现的，插入删除查询时间复杂度都是`O(log(n))`，它的内部是**有序**的，因此需要实现比较操作符(`<`)。

如果你考虑效率，特别是在元素达到一定数量级时，可以考虑使用`unordered_map` 。但若你对内存使用特别严格，希望程序尽可能少消耗内存，那么就要谨慎使用`unordered_map`，因为它占用内存比较大，而且`unordered_map` 的构造速度较慢。


`map`适用于有序数据的应用场景，`unordered_map`适用于高效查询的应用场景

### 内存泄漏的定义，什么时候会造成内存泄漏

内存泄露是指在动态分配内存的过程中，忘记释放掉分配的内存或者因为某些原因导致内存无法释放。如果严重的话会导致系统崩溃发生。

- 比如在一个函数中使用`malloc`函数开辟了`100`个单位的内存空间，并没有释放，如果这个函数频繁地被调用，久而久之就会出现严重的后果，所以在使用完之后应该加上`free`进行释放。

- 如果使用`fopen`打开一个文件，使用完之后没有使用`fclose`进行关闭也会导致内存泄漏。

- 还有没有被初始化的指针也会造成内存泄漏，因为指针未初始化的话它的执行是不可控的。包括错误的释放。比如

```cpp
int *p;  //指针未初始化

int pp = p;
free(pp); //错误释放，这里导致指针p出现指针悬挂现象
```

- 没有将基类的析构函数定义为虚函数，当基类指针指向子类对象时，如果基类的析构函数不是`virtual`，那么子类的析构函数将不会被调用，子类的资源没有正确释放，因此造成内存泄露

### 内存泄漏避免方法

1. **`malloc/free`要配套使用**
2. **使用智能指针** 
3. **将基类的析构函数设为虚函数**

#### 怎么排查

使用内存检测工具

- Valgrind --> 检查内存管理问题
  - memchaeck --> 用于检查程序运行的时候的内存泄漏

### 数组越界问题，怎么解决

- 尽量显式地指定数组的边界

尽量显式地指定数组的边界，即使它已经由初始化值列表隐式指定

- 对数组做越界检查，确保索引值位于合法的范围之内

例如，在写处理数组的函数时，一般应该有一个范围参数；在处理字符串时总检查是否遇到空字符`‘\0`’。

- 获取数组的长度时不要对指针应用 sizeof 操作符

sizeof 是一个单目操作符，不是函数。其作用就是返回一个操作数所占的**内存字节数**。其中，操作数可以是一个表达式或括在括号内的类型名，操作数的存储大小由操作数的类型来决定。例如，对于数组 `int a[5]`，可以使用“`sizeof(a)`”来获取数组的长度，使用“`sizeof(a[0])`”来获取数组元素的长度。

```c
void Init(int arr[])
{
    size_t i=0;
    for(i=0;i<sizeof(arr)/sizeof(arr[0]);i++)
    {
        arr[i]=i;   //这里发生越界了
    }
}
int main(void)
{
    int i=0;
    int a[10];
    Init(a);
    for(i=0;i<10;i++)
    {
        printf("%d\n",a[i]);
    }
    return 0;
}
```

很显然，上面的示例代码在“`void Init(int arr[])`”函数中接收了一个“`int arr[]`”类型的形参，并且在main函数中向它传递一个“`a[10]`”实参。同时，在 Init() 函数中通过“`sizeof(arr)/sizeof(arr[0])`”来确定这个数组元素的数量和初始化值。

在这里出现了一个很大问题：由于 `arr` 参数是一个形参，它是一个指针类型，其结果是“`sizeof(arr)=sizeof(int*)`”。在 IA-32 中，“`sizeof(arr)/sizeof(arr[0])`”的结果为 `1`

我们可以通过传入数组的长度的方式来解决这个问题,我们还可以通过指针的方式来解决上面的问题`void Init(int (*arr)[10])`

- 使用`vector`动态扩容来解决,

> http://c.biancheng.net/view/366.html

## 上海统信一面

### 面向对象的三大特性是：封装，继承和多态。

* **封装**：隐藏了类的实现细节和成员数据，实现了代码模块化，并且类可以把自己的数据和方法只让可信的类或者对象操作，例如：将公共的数据或方法使用`public`修饰，而不希望被访问的数据或方法采用`private`修饰。 `[ˈpraɪvət]`

* **继承**：让子类可以继承父类的成员和方法，实现了代码重用；
  * 常见的继承有三种方式：

  1. 实现继承：指使用基类的属性和方法，子类不需要额外实现
  2. 接口继承：指仅仅使用属性和方法的名称、但是子类必须提供实现的能力
  3. 可视继承：（C++里好像不怎么用，没深入去研究）


* **多态**：是“一个接口，多个实现”，通过父类调用子类的成员，实现了接口重用。如父类的指针指向子类的对象。**多态的实现机制是虚函数+**

#### 面向对象的本质是什么，面向过程是怎么样的

> 面向过程里就解决了复用的问题，定义一个过程（过程、函数）就可以达到复用的目的    
> 
> 面向过程可以达到复用的目的，但是有一个致命的缺点：混乱。定义出来的函数没有层次，没有管理   
>    
> 所以我觉得面向对象的本质就是“管理复用”

### 局部变量和静态变量，局部变量的生命周期

全局变量具有全局作用域。全局变量只需在一个源文件中定义，就可以作用于所有的源文件。当然，其他不包含全局变量定义的源文件需要用`extern`关键字再次声明这个全局变量。

局部变量也只有局部作用域，它是自动对象（auto），它在程序运行期间不是一直存在，而是只在函数执行期间存在，函数的一次调用执行结束后，变量被撤销，其所占用的内存也被收回。

全局变量，静态局部变量，静态全局变量都在**静态存储区**分配空间，而局部变量在栈里分配空间


### static 关键字

`static`的意思是静态的，可以用来修饰变量，函数和类成员。

* 变量：被`static`修饰的变量就是静态变量，它会在程序运行过程中一直存在，会被放在静态区。局部静态变量的作用域在函数体中，全局静态变量的作用域在这个文件里。

* 函数：被`static`修饰的函数就是静态函数，静态函数只能在本文件中使用，不能被其他文件调用，也不会和其他文件中的同名函数冲突。

* 类：而在类中，被`static`修饰的成员变量是类静态成员，这个静态成员会被类的多个对象共用。被`static`修饰的成员函数也属于静态成员，不是属于某个对象的，访问这个静态函数不需要引用对象名，而是通过引用类名来访问。

> **note**: 静态成员函数要访问非静态成员时，要用过对象来引用。局部静态变量在函数调用结束后也不会被回收，会一直在程序内存中，直到该函数再次被调用，它的值还是保持上一次调用结束后的值。

> 注意和`const`的区别。`const`强调值不能被修改，而`static`强调唯一的拷贝，对所有类的对象都共用。

### static 修饰全局变量和普通全局变量的区别

1）全局变量是不显式用 static 修饰的全局变量，全局变量默认是有外部链接性的，作用域是整个工程，在一个文件内定义的全局变量，在另一个文件中，通过 extern 全局变量名的声明，就可以使用全局变量。

2）全局静态变量是显式用 static 修饰的全局变量，作用域是声明此变量所在的文件，其他的文件即使用 extern 声明也不能使用

静态全局变量不能被其它文件所用；其它文件中可以定义相同名字的变量，不会发生冲突。


### 什么是抽象类

一个类中如果有纯虚函数的话，称其为抽象类。抽象类不能用于实例化对象，否则会报错。抽象类一般用于定义一些公有的方法。子类继承抽象类也必须实现其中的纯虚函数才能实例化对象。

使用场景：当这个类本身产生一个实例没有意义的情况下，把这个类的函数实现为纯虚函数，比如动物可以派生出老虎兔子，但是实例化一个动物对象就没有意义。并且可以规定派生的子类必须重写某些函数的情况下可以写成纯虚函数。



### 虚函数和纯虚函数区别

- 虚函数是为了实现动态绑定产生的，目的是通过基类类型的指针指向不同对象时，自动调用相应的、和基类同名的函数（使用同一种调用形式，既能调用派生类又能调用基类的同名函数）。虚函数需要在基类中加上`virtual`修饰符修饰，因为`virtual`会被隐式继承，所以子类中相同函数都是虚函数。当一个成员函数被声明为虚函数之后，其派生类中同名函数自动成为虚函数，在派生类中重新定义此函数时要求函数名、返回值类型、参数个数和类型全部与基类函数相同。

- 纯虚函数只是相当于一个接口名，所以含有纯虚函数的类不能够实例化。



纯虚函数首先是虚函数，其次它**没有函数体**，取而代之的是用“`=0`”。

既然是虚函数，它的函数指针会被存在虚函数表中，由于纯虚函数并没有具体的函数体，因此它在**虚函数表中的值就为`0`**，而具有函数体的虚函数则是函数的具体地址。

一个类中如果有纯虚函数的话，称其为抽象类。抽象类不能用于实例化对象，否则会报错。抽象类一般用于定义一些公有的方法。子类继承抽象类也必须实现其中的纯虚函数才能实例化对象。


### ARP协议说一下

ARP是地址解析协议工作原理：

1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。

2：当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP 地址。

3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。

4：源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

广播发送ARP请求，单播发送ARP响应。

## 好未来 IOS 中台

### 介绍一下堆

堆是一种经过排序的树形数据结构，每个结点都有一个值。通常我们所说的堆的数据结构，是指二叉堆。堆的特点是根结点的值最小（或最大），且根结点的两个子树也是一个堆。由于堆的这个特性，常用来实现优先队列，堆的存取是随意，这就如同我们在图书馆的书架上取书，虽然书的摆放是有顺序的，但是我们想取任意一本时不必像栈一样，先取出前面所有的书，书架这种机制不同于箱子，我们可以直接取出我们想要的书。

### 单线程下会不会发生死锁

> https://blog.csdn.net/u010584319/article/details/79717330
> 其他的前面都重复了


------ 

## 抖音后端21届校招

### 讲了一下线程库（mutex, conditional variable, thread）的C++实现

> https://www.cnblogs.com/lidabo/p/3949465.html


### C++中的多线程

C++11中引入了多线程技术，通过`thread`线程类对象来管理线程，只需要`#include <thread>`即可。`thread`类对象的创建意味着一个线程的开始。

`thread first(线程函数名，参数1，参数2，......)`；每个线程有一个线程函数，线程要做的事情就写在线程函数中。

根据操作系统上的知识，一个进程至少要有一个线程，在C++中可以认为`main`函数就是这个至少的线程，我们称之为**主线程**。而在创建`thread`对象的时候，就是在这个线程之外创建了一个独立的子线程。这里的独立是真正的独立，只要创建了这个子线程并且开始运行了，主线程就完全和它没有关系了，不知道CPU会什么时候调度它运行，什么时候结束运行，一切都是独立，自由而未知的。

- `join()`是一个阻塞函数
- `first.detach()`表示主线程不用等待子线程执行完毕，两者脱离关系。这个一般用在守护线程上：有时候我们需要建立一个暗中观察的线程，默默查询程序的某种状态，这种的称为守护线程。这种线程会在主线程销毁之后自动销毁。

C++中一个标准线程函数只能返回`void`，因此需要从线程中返回值往往采用传递引用的方法


### 设计线程池

> https://www.cnblogs.com/xgmzhna/p/11330995.html

> https://blog.csdn.net/weixin_44189883/article/details/85127723

### 单线程处理多个请求的方式

> IO相关，回答IO的多路复用

### C语言为什么不能进行函数重载

> https://blog.csdn.net/Wan_shibugong/article/details/80740849?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_v2~rank_aggregation-1-80740849.pc_agg_rank_aggregation&utm_term=c%E8%AF%AD%E8%A8%80%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E8%83%BD%E5%87%BD%E6%95%B0%E9%87%8D%E8%BD%BD&spm=1000.2123.3001.4430

### 野指针和悬空指针

都是是指向无效内存区域(这里的无效指的是"不安全不可控")的指针，访问行为将会导致未定义行为。

  + **野指针**   
    野指针，指的是没有被初始化过的指针

    ```cpp
    int main(void) { 
        
        int* p;     // 未初始化
        std::cout<< *p << std::endl; // 未初始化就被使用
        
        return 0;
    }
    ```

    因此，为了防止出错，对于指针初始化时都是赋值为 `nullptr`，这样在使用时编译器就会直接报错，产生非法内存访问。

  + **悬空指针**    
    悬空指针，指针最初指向的内存已经被释放了的一种指针。

    ```cpp
    int main(void) { 
      int * p = nullptr;
    
      int* p2 = new int;
      
      p = p2;
    
      delete p2;
    }
    ```

    此时 `p`和`p2`就是悬空指针，指向的内存已经被释放。继续使用这两个指针，行为不可预料。需要设置为`p=p2=nullptr`。此时再使用，编译器会直接保错。

    避免野指针比较简单，但悬空指针比较麻烦。`c++`引入了智能指针，`C++`智能指针的本质就是避免悬空指针的产生。

    

**产生原因及解决办法**：

- 野指针：指针变量未及时初始化 => 定义指针变量及时初始化，要么置空。

- 悬空指针：指针free或delete之后没有及时置空 => 释放操作后立即置空。

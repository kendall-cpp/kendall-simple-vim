
- [B+树一个节点有多大？一千万条数据，B+树多高](#b树一个节点有多大一千万条数据b树多高)
- [**海量数据问题**](#海量数据问题)
  - [1亿数据数组找最大1万个](#1亿数据数组找最大1万个)
  - [如何冲100亿 URL 中找出相同的 URL](#如何冲100亿-url-中找出相同的-url)
  - [100万url找到出现频率最高的100个](#100万url找到出现频率最高的100个)
  - [40亿个非负整数中找到出现2次的数和所有数的中位数](#40亿个非负整数中找到出现2次的数和所有数的中位数)
- [读取一个500m的文件，并倒序输出，要求内存占用不超过500k](#读取一个500m的文件并倒序输出要求内存占用不超过500k)
- [递归太深有什么影响](#递归太深有什么影响)
- [如何 debug](#如何-debug)
- [函数栈的大小查看，怎么更改大小](#函数栈的大小查看怎么更改大小)
- [怎么遍历能创建一颗唯一的二叉树](#怎么遍历能创建一颗唯一的二叉树)
- [怎么打乱一组数组](#怎么打乱一组数组)

-------

## B+树一个节点有多大？一千万条数据，B+树多高

B+树一个节点的大小设为一页或页的倍数最为合适。因为如果一个节点的大小 `<` 1页，那么读取这个节点的时候其实读取的还是一页，这样就造成了资源的浪费。

在 MySQL 中 B+ 树的一个节点大小为“1页”，也就是`16k`。之所以设置为一页，是因为对于大部分业务，一页就足够了：

首先 InnoDB 的 B+ 树中，非叶子节点存的是`key` + 指针；叶子节点存的是数据行。

- 对于叶子节点，如果一行数据大小为`1k`，那么一页就能存`16`条数据；
- 对于非叶子节点，如果`key`使用的是`bigint`，也就是为`8`字节，指针在`mysql`中为`6`字节，一共是`14`字节，则`16k`能存放 $16 * 1024 / 14 = 1170$ 个索引指针。

于是可以算出，对于一颗高度为`2`的`B+`树，根节点存储索引指针节点，那么它有`1170`个叶子节点存储数据，每个叶子节点可以存储`16`条数据，一共 $1170 * 16 = 18720$ 条数据。

而对于高度为`3`的B+树，就可以存放 $1170 x 1170 x 16 = 21902400$ 条数据（两千多万条数据），也就是对于两千多万条的数据，我们只需要高度为`3`的`B+`树就可以完成，通过主键查询只需要`3`次`IO`操作就能查到对应数据。所以在 InnoDB 中`B+`树高度一般为`3`层时，就能满足千万级的数据存储，所以一个节点为`1`页，也就是`16k`是比较合理的。

## **海量数据问题**

### 1亿数据数组找最大1万个


这道题的思路是，先拿 1w 个数建堆，然后依次添加剩余元素，如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆，这样，遍历完后，堆中的 所有节点的数 就是所需的最大的 1w 个。

**复杂度分析**

建堆时间复杂度是`O(m)`，堆调整的时间复杂度是`O(logm)`，最终时间复杂度等于，`1`次建堆时间`+n`次堆调整时间=`O(m+nlogm)=O(nlogm)`
这里的n为`10`亿，`m`为`1w`

**优化的方法**

可以把所有10亿个数据分组存放，比如分别放在`1000`个文件中。这样处理就可以分别在每个文件的`10^6`个数据中找出最大的`10000`个数，合并到一起在再找出最终的结果。


### 如何冲100亿 URL 中找出相同的 URL

> 问题：给定a、b两个文件，各存放50亿个url，每个url各占64B，内存限制是4GB，请找出a、b两个文件共同的url

由于每个`url`需要占`64B`，所以`50`亿个`url`占用空间大小为`50亿×64=5GB×64=320GB`,由于内存大小只有 4GB，因此不可能一次性把所有的url加载到内存中处理。

对于这种题目，一般采用**分治法**，即把一个文件中的`url`按照某一特征分成多个文件，使得每个文件的内容都小于`4GB`，这样就可以把这个文件一次性读入到内存中进行处理。

**解答**：

首先遍历文件 `a`，对遍历到的 `URL` 求 `hash(URL) % 1000`，根据计算结果把遍历到的 URL 存储到 `a0, a1, a2, ..., a999`，这样每个大小约为 `300MB`。使用同样的方法遍历文件 `b`，把文件 `b` 中的 `URL` 分别存储到文件 `b0, b1, b2, ..., b999` 中。

通过之前的划分，与`ai`中的`url`相同的`url`一定在`bi`中。由于`ai`与`bi`中所有的`url`的大小不会超过`4GB`，因此可以把它们同时读入内存中进行处理。

具体为：遍历文件`ai`，把遍历到的`url`存入`hash_set`中，接着遍历文件`bi`中的`url`，如果这个`url`在`hash_set`中存在，那么说明这个`url`是这两个文件共同的`url`，可以把这个`url`保存到另一个单独的文件中。当把文件`a0~a499`都遍历完成后，就找到了两个文件共同的`url`。

- 分而治之，进行哈希取余；
- 对每个子文件进行 HashSet 统计。

### 100万url找到出现频率最高的100个

> 海量数据中找出出现次数最多的前10个URL（如何找出访问最多的IP，如何从大量数据中找出高频词）

> https://bbs.csdn.net/topics/391080906


关于海量数据问题：

[海量数据处理：如何从10亿个数中，找出最大的10000个数？（top K问题）](https://blog.csdn.net/sinat_42483341/article/details/108277388)

[面试必须掌握的十个海量数据问题及解决方案](https://blog.csdn.net/hitxueliang/article/details/52153476)

### 40亿个非负整数中找到出现2次的数和所有数的中位数

[参考这里](https://blog.csdn.net/aa5305123/article/details/83097006)

1、先建立 new 一个 `bit[]  arr=new bit[4294967295*2]`,长度是数字数量的两倍大小的。

2、遍历这40亿个整数，比如读到 `k` 这个值，那么就让 `arr[k*2]` 和 `arr[k*2+1]`,用`*2`表示所处数组位置，`*2+1`表示出现的次数。当第一次遍历到这两个索引位置`k*2`和`k*2+1`的值分别是 11，也就是 `arr[k*2]=1`, `arr[k*2+1]=1` ，当下次再遇到这个 `k` 值，就更新他们为 1，0.

这里有个巧妙的地方就是，当索引位置 `k*2` 和 `k*2+1` 的值分别是 1 和 0，我们就表示他出现了 2 次。第三次，第四次过来更新的时候需要先判断是否值分别是1，0，如果是就不用做更新了。如果是 0 和 0，那就更新为 1 和 1。如果是 1 和 1 就更新为 1 和 0.

> 经过1，2的处理，我们这个 bit 数组长度为 `4294967295*2` 就很好的表示了所有出现的数，以及他出现的次数是否未出现，或者只出现一次，或者是出现了2次。出现更多次就没法表示了。这样就成功解答了。


## 读取一个500m的文件，并倒序输出，要求内存占用不超过500k

用两个指针，一个 500KBuffer。
- 1.读文件时从后面开始读取 500K，并记录此时的读文件指针位置；
- 2.写文件时从头开始倒写 500K，并记录此时的写文件指针位置；
- 3.从上次读文件的位置读入 500K，从写文件位置再倒写入（重复1，2）；

## 递归太深有什么影响

栈溢出原因：

因为每调用一个方法就会在栈上创建一个栈帧，方法调用结束后就会弹出该栈帧，而栈的大小不是无限的，所以递归调用次数过多的话就会导致栈溢出。

而递归调用的特点是每递归一次，就要创建一个新的栈帧，而且还要保留之前的环境（栈帧），直到遇到结束条件。所以递归调用一定要明确好结束条件，不要出现死循环，而且要避免栈太深。

解决方法：

- 简单粗暴，不要使用递归，使用循环替代。缺点：代码逻辑不够清晰；

- 限制递归次数；

- 使用尾递归，尾递归是指在方法返回时只调用自己本身，且不能包含表达式。编译器或解释器会把尾递归做优化，使递归方法不论调用多少次，都只占用一个栈帧，所以不会出现栈溢出。然鹅，Java 没有尾递归优化。

## 如何 debug

[参考](https://blog.csdn.net/paladinzh/article/details/91354900)

- 输出 log 永远是最简单快捷的调试方式，可以快速定位 bug，通过设置日志级别控制日志的输出详略程度，结合一些文本分析工具 `awk/sed/grep` 可以快速在大量日志中找到错误信息。

- strace: 是一个用来跟踪系统调用的简易工具。它最简单的用途就是跟踪一个程序整个生命周期里所有的系统调用，并把调用参数和返回值以文本的方式输出。Strace还可以跟踪发给进程的信号。支持attach正在运行的进程  `strace -p <pid>`, 当多线程环境下，需要跟踪某个线程的系统调用，可以先ps `-efL|grep <Process Name>` 查找出该进程下的线程，然后调用`starace –p <pid>`进行分析。

- pstack: 用来跟踪进程栈，比如我们发现一个服务一直处于 work 状态（如假死状态，好似死循环），使用这个命令就能轻松定位问题所在；可以在一段时间内，多执行几次pstack，若发现代码栈总是停在同一个位置，那个位置就需要重点关注，很可能就是出问题的地方；

- gdb: 经典的调试工具，功能很强大，注意此时编译的时候应该使用-g选项，并用-Og进行优化。多线程下可以attach到进程来调试。

- valgrind

  包含很多工具：

  Memcheck。这是 valgrind 应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如：使用未初始化的内存，使用已经释放了的内存，内存访问越界等。这也是本文将重点介绍的部分。

  默认使用的就是 memcheck 工具，在 c++ 中指针的使用，一不留神就会产生异常，就可以利用 memcheck 进行检查。个人一般用 `--track-origins=yes` 来定位未初始化变量的位置。



## 函数栈的大小查看，怎么更改大小

- CentOS 系统下可以使用`ulimit -s` 查看当前函数栈大小：

- 使用`ulimit -s sum` 可以将函数栈大小设置为 `sum KB` 大小：


## 怎么遍历能创建一颗唯一的二叉树

中序和前序

中序和后序

中序和层次遍历序列

## 怎么打乱一组数组

> 只写一种

循环随机位法（循环次数最多的打乱数组顺序的方法）

- 创建一个新的数组保存打乱的变量；
- 每次循环产生一个随机位，将随机位的数保存至新数组中；
- 查询新数组中是否存在随机位的数，如果不存在，就保存，如果存在就重新循环该次循环

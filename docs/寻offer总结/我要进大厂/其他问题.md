
- [B+树一个节点有多大？一千万条数据，B+树多高](#b树一个节点有多大一千万条数据b树多高)
- [**海量数据问题**](#海量数据问题)
  - [1亿数据数组找最大1万个](#1亿数据数组找最大1万个)
  - [如何冲100亿 URL 中找出相同的 URL](#如何冲100亿-url-中找出相同的-url)
  - [100万url找到出现频率最高的100个](#100万url找到出现频率最高的100个)
- [递归太深有什么影响](#递归太深有什么影响)
- [如何 debug](#如何-debug)
- [函数栈的大小查看，怎么更改大小](#函数栈的大小查看怎么更改大小)

-------

## B+树一个节点有多大？一千万条数据，B+树多高

B+树一个节点的大小设为一页或页的倍数最为合适。因为如果一个节点的大小 `<` 1页，那么读取这个节点的时候其实读取的还是一页，这样就造成了资源的浪费。

在 MySQL 中 B+ 树的一个节点大小为“1页”，也就是`16k`。之所以设置为一页，是因为对于大部分业务，一页就足够了：

首先 InnoDB 的 B+ 树中，非叶子节点存的是`key` + 指针；叶子节点存的是数据行。

- 对于叶子节点，如果一行数据大小为`1k`，那么一页就能存`16`条数据；
- 对于非叶子节点，如果`key`使用的是`bigint`，也就是为`8`字节，指针在`mysql`中为`6`字节，一共是`14`字节，则`16k`能存放 $16 * 1024 / 14 = 1170$ 个索引指针。

于是可以算出，对于一颗高度为`2`的`B+`树，根节点存储索引指针节点，那么它有`1170`个叶子节点存储数据，每个叶子节点可以存储`16`条数据，一共 $1170 * 16 = 18720$ 条数据。

而对于高度为`3`的B+树，就可以存放 $1170 x 1170 x 16 = 21902400$ 条数据（两千多万条数据），也就是对于两千多万条的数据，我们只需要高度为`3`的`B+`树就可以完成，通过主键查询只需要`3`次`IO`操作就能查到对应数据。所以在 InnoDB 中`B+`树高度一般为`3`层时，就能满足千万级的数据存储，所以一个节点为`1`页，也就是`16k`是比较合理的。

## **海量数据问题**

### 1亿数据数组找最大1万个


这道题的思路是，先拿 1w 个数建堆，然后依次添加剩余元素，如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆，这样，遍历完后，堆中的 所有节点的数 就是所需的最大的 1w 个。

**复杂度分析**

建堆时间复杂度是`O(m)`，堆调整的时间复杂度是`O(logm)`，最终时间复杂度等于，`1`次建堆时间`+n`次堆调整时间=`O(m+nlogm)=O(nlogm)`
这里的n为`10`亿，`m`为`1w`

**优化的方法**

可以把所有10亿个数据分组存放，比如分别放在`1000`个文件中。这样处理就可以分别在每个文件的`10^6`个数据中找出最大的`10000`个数，合并到一起在再找出最终的结果。


### 如何冲100亿 URL 中找出相同的 URL

> 问题：给定a、b两个文件，各存放50亿个url，每个url各占64B，内存限制是4GB，请找出a、b两个文件共同的url

由于每个`url`需要占`64B`，所以`50`亿个`url`占用空间大小为`50亿×64=5GB×64=320GB`,由于内存大小只有 4GB，因此不可能一次性把所有的url加载到内存中处理。

对于这种题目，一般采用**分治法**，即把一个文件中的`url`按照某一特征分成多个文件，使得每个文件的内容都小于`4GB`，这样就可以把这个文件一次性读入到内存中进行处理。

**解答**：

首先遍历文件 `a`，对遍历到的 `URL` 求 `hash(URL) % 1000`，根据计算结果把遍历到的 URL 存储到 `a0, a1, a2, ..., a999`，这样每个大小约为 `300MB`。使用同样的方法遍历文件 `b`，把文件 `b` 中的 `URL` 分别存储到文件 `b0, b1, b2, ..., b999` 中。

通过之前的划分，与`ai`中的`url`相同的`url`一定在`bi`中。由于`ai`与`bi`中所有的`url`的大小不会超过`4GB`，因此可以把它们同时读入内存中进行处理。

具体为：遍历文件`ai`，把遍历到的`url`存`入hash_set`中，接着遍历文件`bi`中的`url`，如果这个`url`在`hash_set`中存在，那么说明这个`url`是这两个文件共同的`url`，可以把这个`url`保存到另一个单独的文件中。当把文件`a0~a499`都遍历完成后，就找到了两个文件共同的`url`。

- 分而治之，进行哈希取余；
- 对每个子文件进行 HashSet 统计。

### 100万url找到出现频率最高的100个

> 海量数据中找出出现次数最多的前10个URL（如何找出访问最多的IP，如何从大量数据中找出高频词）

> https://bbs.csdn.net/topics/391080906


关于海量数据问题：

[海量数据处理：如何从10亿个数中，找出最大的10000个数？（top K问题）](https://blog.csdn.net/sinat_42483341/article/details/108277388)

[面试必须掌握的十个海量数据问题及解决方案](https://blog.csdn.net/hitxueliang/article/details/52153476)

## 递归太深有什么影响

栈溢出原因：

因为每调用一个方法就会在栈上创建一个栈帧，方法调用结束后就会弹出该栈帧，而栈的大小不是无限的，所以递归调用次数过多的话就会导致栈溢出。

而递归调用的特点是每递归一次，就要创建一个新的栈帧，而且还要保留之前的环境（栈帧），直到遇到结束条件。所以递归调用一定要明确好结束条件，不要出现死循环，而且要避免栈太深。

解决方法：

- 简单粗暴，不要使用递归，使用循环替代。缺点：代码逻辑不够清晰；

- 限制递归次数；

- 使用尾递归，尾递归是指在方法返回时只调用自己本身，且不能包含表达式。编译器或解释器会把尾递归做优化，使递归方法不论调用多少次，都只占用一个栈帧，所以不会出现栈溢出。然鹅，Java 没有尾递归优化。

## 如何 debug

https://blog.csdn.net/paladinzh/article/details/91354900

## 函数栈的大小查看，怎么更改大小

- CentOS系统下可以使用`ulimit -s` 查看当前函数栈大小：

- 使用`ulimit -s sum` 可以将函数栈大小设置为 `sum KB` 大小：

- [内存池设计](#内存池设计)
  - [单块内存 io_buf](#单块内存-io_buf)
  - [内存池提供的接口](#内存池提供的接口)
  - [单例模式的连接池](#单例模式的连接池)
  - [从内存池中申请一块内存](#从内存池中申请一块内存)
  - [将一个 io_buf 放回到内存池中](#将一个-io_buf-放回到内存池中)
  - [读写 buffer 机制](#读写-buffer-机制)
- [死锁的产生](#死锁的产生)
  - [利用工具排查死锁问题](#利用工具排查死锁问题)
  - [避免死锁问题的发生](#避免死锁问题的发生)
- [什么是 Reactor 模式](#什么是-reactor-模式)
- [I/O 多路复用技术](#io-多路复用技术)
  - [select/poll](#selectpoll)
  - [epoll](#epoll)
  - [边缘触发和水平触发](#边缘触发和水平触发)
- [设计线程池](#设计线程池)
  - [线程同步的方式](#线程同步的方式)

-----------

## 内存池设计

> 减少使用 malloc  的频率，防止内存泄露和内存碎片，     
> 是一个 map 结构，key -- 内存刻度  value -- 链表 - 内存块      
> io_buf 分成三部分：已处理数据，未处理数据，未使用内存，data->开始，head->数据开始     
> 使用锁（互斥量）保证 pool map 的增删改查，使用单例保证初始化一次


在项目开发过程中，为了避免大量使用 malloc 或者 new 来申请内存，还有为了防止内存泄漏，减少内存碎片的产生，我们设计了一个内存管理机制，也就是内存池。


这个内存是整体是一个 map 数据结构。

- key 对应的是内存的层级，比如：4K,16K,64K
- value 对应的是一个个内存块，这些内存块是通过**链表**来连接起来。

这些内存块中层级越小的会相对多一些，越大的就少一些，整个内存池的大小就是这些内存块大小的总和。

比如说需要分配 3K 的内存，我们就在内存池中找到比 3K 大，并且最接近 3k 的内存块。当一个内存块使用完之后会进行 free 调用，我们实现了一个 free 接口，当使用完这个内存块之后，会将这块内存放回到内存池中。

当 4k 的内存全部用完了，这时候用户还是需要用 4k 内存的时候，内存池就会尝试动态去调用 malloc 进行动态申请。这样可大大较少 malloc 的使用频率。


### 单块内存 io_buf

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结02/内存块01.3g761puxqfk0.png)

整个内存块分成三部分，一部分是已经处理的数据部分，一部分是未处理的数据，也就是有效数据部分，还有一部分是为使用的内存部分（因为，比如用户要使用 3k 的内存，我们分给他的是 4k 的内存块，所以会有一部分内存未被使用）

然后每个内存块都设有两个指针，一个是 data ,指向内存块的首地址，还有一个是 head，指向数据的头部。当开始处理数据时，就移动 head 指针。

### 内存池提供的接口

```cpp
#pragma once

//定义一个 buffer 一块内存的数据结构体

class io_buf{
public:
	//构造函数，创建一个 size 大小的buf
	io_buf(int size);

	//清空数据
	void clear();

	//处理长度为 len 的数据，移动head
	void pop(int len);

	//将已经处理的数据清空(内存抹去), 将未处理的数据 移至 buf的首地址, length会减小
	void adjust();

	//将其他 io_buf 对象拷贝到自己中
	void copy(const io_buf *other);

	~io_buf();
private:
	int capacity;
	int head;
	int length; //当前有效数据长度
	char *data;  // 当前buf内存的首地址
	
	io_buf *next;//存在多个 io_buf 采用链表的形式进行管理

};
```

- 其中 adjust() 函数的作用是：当内存块中所有的数据都处理完了，就将 io_buf 还原。

- copy() 是将另一个 io_buf 的对象拷贝到当前的 io_buf 中。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结02/内存块02.11qfbct3j7bk.png)


### 单例模式的连接池

> 使用 pthread_once_t 保证初始化只执行换一次

从内存池中申请一块内存的时候，会根据申请的内存大小去找到大于或者等于所申请的内存刻度，从链表中摘除出来，如果某个刻度的内存块已经用完了，这时候才真正去使用 malloc 开辟新的内存。

这里为了保证在开辟内存的时候使用 锁[互斥量] 来保护 pool map 的增删改

### 从内存池中申请一块内存

```cpp
io_buf* buf_pool::alloc_buf(int N) {
	//1.找到 N 最近的刻度链表，返回一个 io_buf
	int index;
	if(N <= m4K){
		index = m4K;
	}
	else if(N < m16K) {
		index = m16K;
    }
    else if ( N <= m64K) {
        index = m64K;
    }
    else if ( N <= m256K) {
        index = m256K;
    }
    else if ( N <= m1M) {
        index = m1M;
    }
    else if ( N <= m4M) {
        index = m4M;
    }
    else if ( N <= m8M) {
        index = m8M;
    }
    else {
        return NULL;
    }
	//2.如果该index已经没有内存了，需要额外的申请内存
	//需要加锁保证 pool map 的增删改
	pthread_mutex_lock(&_mutex);
	if(_pool[index] == NULL) {
		if(_total_num + index / 1024 >= MEM_LIMIT ) {
			fprintf(stderr,"already use too many memory\n");
			exit(1);
		}
		//没有了就要重新申请内存
		io_buf *new_buf = new io_buf(index);
		if(new_buf == NULL) {
			fprintf(stderr,"new io_buf error\n");
			exit(1);
		}
		_total_num += index / 1024;
		pthread_mutex_unlock(&_mutex);
		return new_buf;  //返回性开辟的内存块
	}
	//如果有内存块，就从内存池的链表中取出内存块
	io_buf *target = _pool[index];
	//移动内存链表的头地址
	_pool[index] = target->next;

	pthread_mutex_unlock(&_mutex);

	target->next = NULL;
	return target;
	
}
io_buf* buf_pool::alloc_buf() {
	// 不传递就默认 m4K
	return alloc_buf(m4K);
}
```

- 先找到最接近要取出内存大小的内存刻度链表
- 如果内存池中这个内存刻度的内存块已经用完了，就重新开辟新的内存块并返回
- 如果这个刻度的内存块还有，就将第一个内存块取出来并返回

> 注意需要加锁保证内存池的增删改

### 将一个 io_buf 放回到内存池中

```cpp
void buf_pool::revert(io_buf* buffer) {
	//将buffer放回到 pool 中
	//index 属于 pool 中的哪个刻度链表
	int index = buffer->capacity;
	//1.内存块恢复默认值,没有有效数据，即 length  = 0
	buffer->head = 0;
	buffer->length = 0;

	//断言，一定要找到 index，也就是 map 的 key
	assert(_pool.find(index) != _pool.end() );

	pthread_mutex_lock(&_mutex);
	//2.将 buffer 放到对应刻度链表的头部
	buffer->next = _pool[index];
	_pool[index] = buffer;

	pthread_mutex_unlock(&_mutex);
}
```

- 首先找到对应的刻度链表
- 然后这这个内存块恢复默认值（`head = 0,lenght = 0`)
- 将这个内存块使用头插法插入到对应的刻度链表中

> 注意这里也要加锁保证内存池的增删改

### 读写 buffer 机制

```cpp

//从一个fd中读取数据到reactor_buf中
int input_buf::read_data(int fd)
{
    int need_read; //硬件中更有多少数据是可以都的

    //一次性将io中的缓存数据全部都出来
    //需要给fd设置一个属性
    //传出一个参数,目前缓冲中一共有多少数据是可读
    if (ioctl(fd, FIONREAD, &need_read) == -1) {
        fprintf(stderr, "ioctl FIONREAD\n");
        return -1;
    }


    if (_buf == NULL) {
        //如果当前的input_buf里的_buf是空，需要从buf_pool拿一个新的
        _buf = buf_pool::instance()->alloc_buf(need_read);
        if (_buf == NULL) {
            fprintf(stderr, "no buf for alloc!\n");
            return -1;
        }
    }
    else {
        //如果当前buf可用,判断一下当前buf是否够存
        assert(_buf->head == 0);
        if (_buf->capacity - _buf->length < need_read) {
            //不够存
            io_buf *new_buf = buf_pool::instance()->alloc_buf(need_read+_buf->length);
            if (new_buf == NULL) {
                fprintf(stderr, "no buf for alloc\n");
                return -1;
            }

            //将之前的_buf数据拷贝到新的buf中
            new_buf->copy(_buf);
            //将之前的_buf 放回内存池中
            buf_pool::instance()->revert(_buf);
            //新申请的buf称为当前的io_buf
            _buf = new_buf;
        }
    }

    int already_read = 0;

    //当前的buf是可以容纳  读取数据
    do {
        if (need_read == 0) {
            already_read = read(fd, _buf->data + _buf->length, m4K);//阻塞直到有数据
        }
        else {
            already_read = read(fd, _buf->data + _buf->length, need_read);
        }
    } while(already_read == -1 && errno == EINTR);//systemcall一个终端，良性，需要继续读取


    if (already_read > 0) {
        if (need_read != 0) {
            assert(already_read == need_read);
        }

        //读数据已经成功
        _buf->length += already_read;
    }

    return already_read;
}

//获取当前的数据的方法
const char *input_buf::data()
{
    return _buf != NULL ? _buf->data + _buf->head : NULL;
}

//重置缓冲区
void input_buf::adjust()
{
    if (_buf != NULL) {
        _buf->adjust();
    }
}

// =========================================== 
    //将一段数据 写到 自身的_buf中
int output_buf::send_data(const char *data, int datalen)
{
    if (_buf == NULL) {
        //如果当前的output_buf里的_buf是空，需要从buf_pool拿一个新的
        _buf = buf_pool::instance()->alloc_buf(datalen);
        if (_buf == NULL) {
            fprintf(stderr, "no buf for alloc!\n");
            return -1;
        }
    }
    else {
        //如果当前buf可用,判断一下当前buf是否够存
        assert(_buf->head == 0);

        if (_buf->capacity - _buf->length < datalen) {
            //不够存
            io_buf *new_buf = buf_pool::instance()->alloc_buf(datalen+_buf->length);
            if (new_buf == NULL) {
                fprintf(stderr, "no buf for alloc\n");
                return -1;
            }

            //将之前的_buf数据拷贝到新的buf中
            new_buf->copy(_buf);
            //将之前的_buf 放回内存池中
            buf_pool::instance()->revert(_buf);
            //新申请的buf称为当前的io_buf
            _buf = new_buf;
        }
    }

    //将data 数据写到io_buf中 拼接到后面    
    memcpy(_buf->data + _buf->length, data, datalen);
    _buf->length += datalen;

    return 0;
}

//将_buf中的数据写到一个fd中
int output_buf::write2fd(int fd) //取代 io层 write方法
{
    assert(_buf != NULL && _buf->head == 0);

    int already_write = 0;

    do {
        already_write = write(fd, _buf->data, _buf->length);
    } while (already_write == -1 && errno == EINTR);//系统调用中断产生，不是一个错误


    if (already_write > 0) {
        //已经写成功
        _buf->pop(already_write);
        _buf->adjust();
    }


    //如果fd是非阻塞的,会报already_write==-1 errno==EAGAIN
    if (already_write == -1 && errno == EAGAIN) {
        already_write = 0;//表示非阻塞导致的-1 不是一个错误,表示是正确的只是写0个字节
    }

    return already_write;
}
```

## 死锁的产生

两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。

死锁只有同时满足以下四个条件才会发生：

- **互斥条件**；多个线程不能同时使用同一个资源，如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源

- 持有并等待条件；线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。

- 不可剥夺条件；当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。

- 环路等待条件；线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。

### 利用工具排查死锁问题

在 Linux 下，我们可以使用 pstack 工具来定位死锁问题。

pstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 `pstack <pid>` 就可以了。

那么，在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。

### 避免死锁问题的发生

产生死锁的四个必要条件是：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。

避免死锁问题就只需要破环其中一个条件就可以。

最常用的方法就是使用资源有序分配法来破坏环路等待条件。

- 安全序列
	- 主要能找到一个安全系列，那么系统就属于安全状态的。
	- 在系统进入安全状态下是一定不会发生死锁的。但是如果属于不安全状态，有可能会发生死锁。

> 我们在分配资源之前，预先判断一下，这次分配是否会导致系统进入不安全状态，根据这个来决定手否答应资源分配请求。这也是银行家算法的思想。

- 银行家算法
  - 尝试找一个安全系列， 
  - 依次检查剩余的资源是否满足各个进程的需求，
  - 如果可以满足 P1 的需求，那就把资源全部分配给 P1 进程，等 P1 执行结束了就会归还 P1 持有的资源，
  - 接着又检查是否满足 P2 的需求，如果满足就把 P2 加入安全序列，并更新剩余可用资源
  - 最后知道包含所有进程的安全序列
  - 这时候系统是属于安全状态的，因此不会发生死锁

##  什么是 Reactor 模式


如果说让服务器服务多个客户端，那么最直接的方式就是一个连接创建一个线程，处理完成后关闭连接，线程销毁，但是这样会带来很大的性能开销，也会浪费资源，当然我们也可以使用「资源复用」，也就是创建一个线程池，这样就不用每个连接都分配一个线程，可以创建一个线程多个连接复用。

但是引入了线程池，那么一个线程要处理多个连接的业务，线程在处理某个连接的 read 操作时，如果遇到没有数据可读，就会发生阻塞，那么线程就没办法继续处理其他连接的业务。

要解决这一个问题，最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 read 操作来判断是否有数据，这种方式虽然该能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的，而且随着一个 线程处理的连接越多，轮询的效率就会越低。

所以采用 I/O 多路复用，只有当连接上有数据的时候，线程才去发起读请求

> `select/poll/epoll` 是如何获取网络事件的呢？

在获取事件时，先把我们要关心的连接传给内核，再由内核检测：

- 如果没有事件发生，线程只需阻塞在这个系统调用，而无需像前面的线程池方案那样轮训调用 read 操作来判断是否有数据。
- 如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态返回，然后在用户态中再处理这些连接对应的业务即可。

**Reactor 模式** 就是基于面向对象的思想，对 I/O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写。

Reactor 模式主要由 **Reactor** 和**处理资源池**这两个核心部分组成，它俩负责的事情如下：
- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send

## I/O 多路复用技术

 `I/O` 多路复用技术就是用一个进程来维护多个 `Socket`。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/IO复用01.4ns3czhz0sk0.png)


一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用。

比较常见的多路复用技术有 `select/poll/epoll`


### select/poll

`select` 将已连接的 `Socket` 都放到一个文件描述符集合，然后调用 `select` 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 `Socket` 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 `Socket`，然后再对其处理。

所以，对于 `select` 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符**集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

`select` 所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 `FD_SETSIZE` 限制， 默认最大值为 `1024`。

`poll` 以链表形式来组织文件描述符，解决了 `select` 的文件描述符个数限制的问题，当然还会受到系统文件描述符限制。

但是 `poll` 和 `select` 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 `Socket` 集合，因此都需要遍历文件描述符集合来找到 可读 或 可写 的 `Socket`，时间复杂度为 `O(n)`，而且也需要在 用户态 与 内核态 之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。

### epoll

**Epoll 就是一种在 Linux 上使用的 IO 多路复用并支持高并发的典型技术**。

比如说有 10 万个并发连接（也就是同一时刻有 10 万个客户端保持和服务器的连接），这 10 万个连接通常也不可能同一时刻都在收发数据，一般在**同一时刻通常只有其中几十个或者几百个连接在收发数据，其他连接可能处于只连接而没有收发数据的状态**。

如果以 100ms 为间隔判断一次，可能这 100ms 内只有 100 个活跃连接（就是有数据收发的连接），把这 100 个活跃连接的数据放在一个专门的地方，后续到这个专门的地方来，只需要处理 100 条数据，处理起来的压力就没那么大了。

这也就是 Epoll 的处理方式。而 select 和 poll 是依次判断这 10w 个连接有没有收发数据（可能实际上有数据的只有 100 个连接），有数据就处理。所以不难看出每次检查 10w 个连接与每次检查 100 个连接相比，浪费了巨大的资源和时间。

> 实际上，`epoll` 在内核里使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的 `socket` 通过 `epoll_ctl()` 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 `O(logn)`，通过对这棵黑红树进行操作，这样就不需要像 `select/poll` 每次操作时都传入整个 `socket` 集合，只需要传入一个待检测的 `socket` 就可以了，减少了内核和用户空间大量的数据拷贝和内存分配。


此外 Epoll 采用了 **事件驱动机制**，只在单独的进程或者线程里收集和处理各种事件，没有进程或线程之间上下文切换的开销。

> 也就是说，在内核中维护了一个「链表」来记录就绪事件，当某个 `socket` 有事件发生时候，通过回调函数，内核会将这个 事件 加入到 就绪事件 列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件的 socket 文件描述符，不需要像 `select/poll` 那样轮询扫描整个` socket` 集合，大大提高了检测的效率。

`epoll` 通过两个方面，很好解决了 `select/poll` 的问题。

从下图你可以看到 `epoll` 相关的接口作用：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/epoll01.58ud4l3nxm00.png)

### 边缘触发和水平触发

`epoll` 支持两种事件触发模式，分别是**边缘触发**（edge-triggered，**ET**）和**水平触发**（level-triggered，**LT**）。

这两个术语还挺抽象的，其实它们的区别还是很好理解的。

- 使用**边缘触发模式**时，当被监控的 `Socket` 描述符上有可读事件发生时，服务器端只会从 `epoll_wait` 中苏醒一次，即使进程没有调用 `read` 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；

- 使用**水平触发模式**时，当被监控的 `Socket` 上有可读事件发生时，服务器端不断地从 `epoll_wait` 中苏醒，直到内核缓冲区数据被 `read` 函数读完才结束，目的是告诉我们有数据需要读取；


> 边缘触发：从不可读变为可读，从可读变为不可读，从不可写变为可写，从可写变为不可写，都只触发一次    
> 水平触发：只要可读，就一直触发读事件，只要可写，就一直触发写事件

这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。

如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。

如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 `read` 和 `write`）返回错误，错误类型为 `EAGAIN` 或 `EWOULDBLOCK`。

一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 `epoll_wait` 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。

`select/poll` 只有水平触发模式，`epoll` **默认的触发模式是水平触发**，但是可以根据应用场景设置为边缘触发模式。


## 设计线程池


### 线程同步的方式

实现线程间同步的方法：

**互斥量，自旋锁，读写锁，条件变量**

- **互斥量**：比如说有两个线程，线程 1 和线程 2，分别充当生产者与消费者的角色，那么这两个线程就很有可能同时去操作临界资源，如果同时去操作临界资源的话就会引起线程同步问题，互斥量的话就是来解决这个问题，当一个线程，比如说线程 1 在操作临界资源的时候，它就会阻止另外的线程去访问这个临界资源。其实引发线程同步问题的最根本原因是**这两个线程的指令是交叉执行的**，互斥量能够保证指令执行的原子性，也就是说先执行完线程 1 的指令再执行线程2的指令，或者先执行完线程 2 的指令再执行线程1的指令。保证他们之间不会出现交叉执行的情况。互斥量也称为**互斥锁**，它要么处于加锁状态要么处于解锁状态。保证资源访问的串行。操作系统提供的 API 是 `pthread_mutex_t`。

- **自旋锁**：其实自旋锁和互斥锁的原理是一样的，都是在使用临界资源之前加一个锁，阻止其他线程对它进行访问，完成之后再把锁给释放掉，保证临界资源的串行访问。但是它和互斥锁还是存在差别的，使用自旋锁的线程会一直循环反复检查锁的变量是否可用，因此**它不会让出CPU**，会处于忙等待的状态。其实自旋锁还是有很多好处的，它避免了进程或者线程上下文切换的开销，如果锁使用的时间不是很长的话，使用自旋锁的代价也是很小的，同时在操作系统内部很多地方使用的是自旋锁而不是互斥量的。这里还要提一点就是**自旋锁不适合在单核`CPU`中使用**。因为自旋锁在等待的时候并不会释放`CPU`，而是死循环地去等待。会引起其他的进程或者线程无法去执行。操作系统提供的API是`pthread_spinock_t`。

- **读写锁**: 读写锁和互斥锁还有自旋锁是类似的，但是做了一些改进，基于临界资源的考量，因为在开发环境中，临界资源很可能会出现多读少写的特性，就比如有一个数据库存储的是历史订单信息，而这些订单我们一般只是去查询很少去改变它，这个存储历史订单的数据库就属于多读少写的临界资源，如果在读写的时候也给它加锁，这样的话效率会很低的。读写锁的话是一种特殊的自旋锁，**它允许多个读者同时读取临界资源，但是不允许多个写操作同时访问这个资源**。在操作系统中提供的API是`thread_rwlock_t`，读锁是通过`thread_rwlock_rdlock`来加的，写锁是通过`thread_rwlock_wdlock`来加的.

- **条件变量**：条件变量是一种先对复杂的线程同步方法，它允许线程睡眠，在满足一定条件的时候再唤醒线程，就是当满足条件时，可以向这个线程发送信号，唤醒这个线程。因为在生产者和消费者模型中是存在问题的，举个例子，比如当缓冲区小于或者等于 0 时，这时候应该不允许消费者继续消费，消费者必须等待，当缓冲区满的时候，这个时候应该不允许生产者往里面生成数据了，生产者必须处于等待状态。条件变量呢就是对这个问题进行了约束，当缓冲区为 0 的时候，如果有生产者生产一个产品，那么就要唤醒可能等待的消费者；当缓冲区满的时候，如果有消费者消费了产品，就需要唤醒其他可能在等待的生产者。操作系统提供的`API`是`pthread_cont_t`来定义的,等待是通过`pthread_cont_wait`定义的，,唤醒是通过`pthread_cont_notify`定义的。

> 互斥量：保证只有一个进程去操作 临界资源，同步问题是因为两个指令交叉执行，所以需要保证原子性。   
> 自旋锁：加锁，保证串行执行，但是不会让出 CPU ，反复检查锁是是否可用，     
> 读写锁：考虑临界资源多读少写，允许多读不允许多写      
> 条件变量：适当的时候唤醒线程，缓冲区为 0 消费者等待，缓冲区满了，生产者等待






